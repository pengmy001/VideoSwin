{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pengmy001/VideoSwin/blob/main/vslr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k6bkm3TK30i",
        "outputId": "a4e30f81-23dd-4311-9fe2-de76f4e4ae65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ8TlOMmLR0a",
        "outputId": "cade79a0-f7dd-48b8-a506-151536ce3880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd7MhexQLSUw",
        "outputId": "f32aaaef-e5f5-4ca5-9e01-8bb999a5aa35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1NGc_AhpYbtXwsERLnGHUwsUHrAPuyqR5/new\n",
            "['vis2pan', 'res', 'lr', 'pres_loss.txt', 'pres_val_loss.txt', 'modelvs_auth.png']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-a8c10a41ec1c>:815: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if lr_train == []:\n",
            "<ipython-input-3-a8c10a41ec1c>:821: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if lr_pred == []:\n",
            "<ipython-input-3-a8c10a41ec1c>:828: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if vs_train == []:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2320, 64, 64, 1)\n",
            "(2320, 64, 64, 1)\n",
            "(2320, 64, 64, 1)\n",
            "data read!\n",
            "[[4], [6, 6], [8, 16, 8, 16]]\n",
            "[[<class '__main__.NCB'>], [<class '__main__.NCB'>, <class '__main__.NCB'>], [<class '__main__.NCB'>, <class '__main__.NTB'>, <class '__main__.NCB'>, <class '__main__.NTB'>]]\n",
            "4\n",
            "<class '__main__.NCB'>\n",
            "4\n",
            "6\n",
            "<class '__main__.NCB'>\n",
            "6\n",
            "6\n",
            "<class '__main__.NCB'>\n",
            "6\n",
            "8\n",
            "<class '__main__.NCB'>\n",
            "8\n",
            "16\n",
            "<class '__main__.NTB'>\n",
            "12\n",
            "12\n",
            "4\n",
            "4\n",
            "6\n",
            "6\n",
            "8\n",
            "12\n",
            "12\n",
            "4\n",
            "4\n",
            "6\n",
            "6\n",
            "8\n",
            "12\n",
            "12\n",
            "4\n",
            "model built!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2320, 64, 64, 1)\n",
            "(2320, 64, 64, 1)\n",
            "(2320, 64, 64, 1)\n",
            "Epoch 1/1000\n",
            "522/522 [==============================] - 205s 304ms/step - loss: 0.6593 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "522/522 [==============================] - 163s 312ms/step - loss: 0.1816 - accuracy: 0.0000e+00 - val_loss: 0.1014 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "522/522 [==============================] - 166s 319ms/step - loss: 0.1040 - accuracy: 0.0000e+00 - val_loss: 0.0378 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "522/522 [==============================] - 163s 313ms/step - loss: 0.0941 - accuracy: 0.0000e+00 - val_loss: 0.1001 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "522/522 [==============================] - 168s 322ms/step - loss: 0.0953 - accuracy: 0.0000e+00 - val_loss: 0.1042 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "522/522 [==============================] - 167s 321ms/step - loss: 0.0964 - accuracy: 0.0000e+00 - val_loss: 0.0416 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "522/522 [==============================] - 163s 313ms/step - loss: 0.0922 - accuracy: 0.0000e+00 - val_loss: 0.0333 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "522/522 [==============================] - 167s 320ms/step - loss: 0.0907 - accuracy: 0.0000e+00 - val_loss: 0.0519 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "522/522 [==============================] - 170s 325ms/step - loss: 0.0878 - accuracy: 0.0000e+00 - val_loss: 0.0386 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "522/522 [==============================] - 164s 314ms/step - loss: 0.0933 - accuracy: 0.0000e+00 - val_loss: 0.0243 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "522/522 [==============================] - 168s 321ms/step - loss: 0.0898 - accuracy: 0.0000e+00 - val_loss: 0.0253 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "522/522 [==============================] - 168s 323ms/step - loss: 0.0861 - accuracy: 0.0000e+00 - val_loss: 0.0299 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "522/522 [==============================] - 164s 315ms/step - loss: 0.0929 - accuracy: 0.0000e+00 - val_loss: 0.0936 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "522/522 [==============================] - 164s 314ms/step - loss: 0.0890 - accuracy: 0.0000e+00 - val_loss: 0.0214 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "522/522 [==============================] - 168s 323ms/step - loss: 0.0945 - accuracy: 0.0000e+00 - val_loss: 1.8894 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "522/522 [==============================] - 164s 314ms/step - loss: 0.0918 - accuracy: 0.0000e+00 - val_loss: 0.0301 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "522/522 [==============================] - 164s 315ms/step - loss: 0.0877 - accuracy: 0.0000e+00 - val_loss: 0.0228 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "522/522 [==============================] - 168s 322ms/step - loss: 0.0885 - accuracy: 0.0000e+00 - val_loss: 0.0275 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "522/522 [==============================] - 164s 314ms/step - loss: 0.0860 - accuracy: 0.0000e+00 - val_loss: 0.0200 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "522/522 [==============================] - 168s 322ms/step - loss: 0.0866 - accuracy: 0.0000e+00 - val_loss: 130.8652 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "522/522 [==============================] - 168s 321ms/step - loss: 0.0876 - accuracy: 0.0000e+00 - val_loss: 0.0393 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "522/522 [==============================] - 167s 321ms/step - loss: 0.0872 - accuracy: 0.0000e+00 - val_loss: 0.0521 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 23/1000\n",
            "522/522 [==============================] - 168s 321ms/step - loss: 0.0842 - accuracy: 0.0000e+00 - val_loss: 0.0303 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 24/1000\n",
            "522/522 [==============================] - 164s 313ms/step - loss: 0.0881 - accuracy: 0.0000e+00 - val_loss: 0.0213 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 25/1000\n",
            "522/522 [==============================] - 169s 323ms/step - loss: 0.0828 - accuracy: 0.0000e+00 - val_loss: 0.0291 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 26/1000\n",
            "522/522 [==============================] - 169s 323ms/step - loss: 0.0823 - accuracy: 0.0000e+00 - val_loss: 0.0246 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 27/1000\n",
            "522/522 [==============================] - 171s 327ms/step - loss: 0.0862 - accuracy: 0.0000e+00 - val_loss: 0.0282 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 28/1000\n",
            "522/522 [==============================] - 169s 324ms/step - loss: 0.0861 - accuracy: 0.0000e+00 - val_loss: 0.0331 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 29/1000\n",
            "522/522 [==============================] - 165s 317ms/step - loss: 0.0834 - accuracy: 0.0000e+00 - val_loss: 0.0282 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 30/1000\n",
            "522/522 [==============================] - 172s 329ms/step - loss: 0.0887 - accuracy: 0.0000e+00 - val_loss: 0.0335 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 31/1000\n",
            "522/522 [==============================] - 169s 324ms/step - loss: 0.0897 - accuracy: 0.0000e+00 - val_loss: 0.1334 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 32/1000\n",
            "522/522 [==============================] - 169s 323ms/step - loss: 0.0876 - accuracy: 0.0000e+00 - val_loss: 0.0192 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 33/1000\n",
            "522/522 [==============================] - 164s 314ms/step - loss: 0.0877 - accuracy: 0.0000e+00 - val_loss: 0.0279 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 34/1000\n",
            "522/522 [==============================] - 168s 321ms/step - loss: 0.0866 - accuracy: 0.0000e+00 - val_loss: 0.0184 - val_accuracy: 0.0000e+00 - lr: 2.0000e-04\n",
            "Epoch 35/1000\n",
            "522/522 [==============================] - 171s 328ms/step - loss: 0.0878 - accuracy: 0.0000e+00 - val_loss: 0.0178 - val_accuracy: 0.0000e+00 - lr: 2.0000e-04\n",
            "Epoch 36/1000\n",
            "522/522 [==============================] - 172s 330ms/step - loss: 0.0860 - accuracy: 0.0000e+00 - val_loss: 0.0174 - val_accuracy: 0.0000e+00 - lr: 2.0000e-04\n",
            "Epoch 37/1000\n",
            "522/522 [==============================] - 169s 324ms/step - loss: 0.0834 - accuracy: 0.0000e+00 - val_loss: 0.0191 - val_accuracy: 0.0000e+00 - lr: 2.0000e-04\n",
            "Epoch 38/1000\n",
            "522/522 [==============================] - 172s 330ms/step - loss: 0.0826 - accuracy: 0.0000e+00 - val_loss: 0.0174 - val_accuracy: 0.0000e+00 - lr: 2.0000e-04\n",
            "Epoch 39/1000\n",
            "522/522 [==============================] - 168s 322ms/step - loss: 0.0872 - accuracy: 0.0000e+00 - val_loss: 0.0185 - val_accuracy: 0.0000e+00 - lr: 2.0000e-04\n",
            "Epoch 40/1000\n",
            "522/522 [==============================] - 171s 328ms/step - loss: 0.0883 - accuracy: 0.0000e+00 - val_loss: 0.0194 - val_accuracy: 0.0000e+00 - lr: 2.0000e-04\n",
            "Epoch 41/1000\n",
            "522/522 [==============================] - 169s 324ms/step - loss: 0.0819 - accuracy: 0.0000e+00 - val_loss: 0.0176 - val_accuracy: 0.0000e+00 - lr: 4.0000e-05\n",
            "Epoch 42/1000\n",
            "522/522 [==============================] - 169s 324ms/step - loss: 0.0793 - accuracy: 0.0000e+00 - val_loss: 0.0173 - val_accuracy: 0.0000e+00 - lr: 4.0000e-05\n",
            "Epoch 43/1000\n",
            "522/522 [==============================] - 174s 333ms/step - loss: 0.0854 - accuracy: 0.0000e+00 - val_loss: 0.0177 - val_accuracy: 0.0000e+00 - lr: 4.0000e-05\n",
            "Epoch 44/1000\n",
            "200/522 [==========>...................] - ETA: 1:37 - loss: 0.0855 - accuracy: 0.0000e+00"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from einops import rearrange\n",
        "from keras.layers import Input\n",
        "from typing import List, Union\n",
        "import os\n",
        "from osgeo import gdal\n",
        "import numpy as np\n",
        "import math\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.utils import plot_model\n",
        "import datetime\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "\n",
        "EPSILON = 1e-5\n",
        "\n",
        "\n",
        "CONFIG = {\n",
        "    \"SMALL\": {\n",
        "        \"stem_chs\": [32,16,32],\n",
        "        \"depths\": [1,2,2],\n",
        "        \"drop_path\": 0.1,\n",
        "    },\n",
        "    \"BASE\": {\n",
        "        \"stem_chs\": [64, 32, 64],\n",
        "        \"depths\": [3, 4, 20, 3],\n",
        "        \"drop_path\": 0.1,\n",
        "    },\n",
        "    \"LARGE\": {\n",
        "        \"stem_chs\": [64, 32, 64],\n",
        "        \"depths\": [3, 4, 30, 3],\n",
        "        \"drop_path\": 0.1,\n",
        "    },\n",
        "}\n",
        "#\"SMALL\": {\n",
        "#        \"stem_chs\": [64, 32, 64],\n",
        "#        \"depths\": [3, 4, 10, 3],\n",
        "#        \"drop_path\": 0.1,\n",
        "#    },\n",
        "# https://github.com/huggingface/transformers/blob/60d51ef5123d949fd8c59cd4d3254e711541d278/src/transformers/tf_utils.py#L26\n",
        "def shape_list(tensor: Union[tf.Tensor, np.ndarray]) -> List[int]:\n",
        "    if isinstance(tensor, np.ndarray):\n",
        "        return list(tensor.shape)\n",
        "    dynamic = tf.shape(tensor)\n",
        "    if tensor.shape == tf.TensorShape(None):\n",
        "        return dynamic\n",
        "    static = tensor.shape.as_list()\n",
        "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
        "\n",
        "\n",
        "class E_MHSA(layers.Layer):\n",
        "    \"\"\"\n",
        "    Efficient Multi-Head Self Attention\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        out_dim=None,\n",
        "        head_dim=2,\n",
        "        qkv_bias=True,\n",
        "        qk_scale=None,\n",
        "        attn_drop=0,\n",
        "        proj_drop=0.0,\n",
        "        sr_ratio=1,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.out_dim = out_dim if out_dim is not None else dim\n",
        "        self.num_heads = self.dim // head_dim\n",
        "        self.scale = qk_scale or head_dim**-0.5\n",
        "        self.q = tf.keras.layers.Dense(dim, use_bias=qkv_bias)\n",
        "        self.k = tf.keras.layers.Dense(dim, use_bias=qkv_bias)\n",
        "        self.v = tf.keras.layers.Dense(dim, use_bias=qkv_bias)\n",
        "        self.proj = tf.keras.layers.Dense(self.out_dim)\n",
        "        self.attn_drop = tf.keras.layers.Dropout(attn_drop)\n",
        "        self.proj_drop = tf.keras.layers.Dropout(proj_drop)\n",
        "\n",
        "        self.sr_ratio = sr_ratio\n",
        "        self.N_ratio = sr_ratio**2\n",
        "        if sr_ratio > 1:\n",
        "            self.sr = tf.keras.layers.AveragePooling1D(\n",
        "                pool_size=self.N_ratio, strides=self.N_ratio\n",
        "            )\n",
        "            self.norm = tf.keras.layers.BatchNormalization(epsilon=1e-5)\n",
        "\n",
        "    def call(self, x):\n",
        "        B = shape_list(x)[0]\n",
        "        N = shape_list(x)[1]\n",
        "        C = shape_list(x)[2]\n",
        "        q = self.q(x)\n",
        "        q = tf.reshape(q, (B, N, self.num_heads, int(C // self.num_heads)))\n",
        "        q = tf.transpose(q, perm=[0, 2, 1, 3])\n",
        "\n",
        "        if self.sr_ratio > 1:\n",
        "            x_ = tf.transpose(x, perm=[0, 2, 1])\n",
        "            #x_ = self.sr(x_)\n",
        "            x_ = tf.transpose(x_, perm=[0, 2, 1])\n",
        "            k = self.k(x_)\n",
        "            k = tf.reshape(k, (B, -1, self.num_heads, C // self.num_heads))\n",
        "            k = tf.transpose(k, perm=[0, 2, 3, 1])\n",
        "            v = self.v(x_)\n",
        "            v = tf.reshape(v, (B, -1, self.num_heads, C // self.num_heads))\n",
        "            v = tf.transpose(v, perm=[0, 2, 1, 3])\n",
        "        else:\n",
        "            k = self.k(x)\n",
        "            k = tf.reshape(k, (B, -1, self.num_heads, C // self.num_heads))\n",
        "            k = tf.transpose(k, perm=[0, 2, 3, 1])\n",
        "            v = self.v(x)\n",
        "            v = tf.reshape(v, (B, -1, self.num_heads, C // self.num_heads))\n",
        "            v = tf.transpose(v, perm=[0, 2, 1, 3])\n",
        "        attn = tf.matmul(q, k) * self.scale\n",
        "\n",
        "        #attn = tf.nn.softmax(attn, axis=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = tf.matmul(attn, v)\n",
        "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "        x = tf.reshape(x, (B, N, C))\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def NextViT_2b(\n",
        "    input_shape1, input_shape2, stem_chs, depths, path_dropout,out_chans,\n",
        ") -> keras.Model:\n",
        "    strides = [1, 1, 1] #[1, 2, 2, 2]\n",
        "    sr_ratios = [4, 2, 1]\n",
        "    input_layer1 = layers.Input(input_shape1)\n",
        "    input_layer2 = layers.Input(input_shape2)\n",
        "    #input_layer1 = layers.Input((256,256,32))\n",
        "    #input_layer2 = layers.Input((256,256,14))\n",
        "\n",
        "    stem1 = tf.keras.Sequential(\n",
        "        [\n",
        "            ConvBNReLU(stem_chs[0], kernel_size=3, strides=1),#2\n",
        "            ConvBNReLU(stem_chs[1], kernel_size=3, strides=1),\n",
        "            #ConvBNReLU(stem_chs[2], kernel_size=3, strides=1),\n",
        "            ConvBNReLU(stem_chs[2], kernel_size=3, strides=1),#2\n",
        "        ]\n",
        "    )\n",
        "    x1 = stem1(input_layer1)\n",
        "\n",
        "    '''stage_out_channels = [\n",
        "        [4] * (depths[0]),\n",
        "        [8] * (depths[1] - 1) + [8],\n",
        "        [16, 32] * (depths[2] // 1),\n",
        "        #[16] * (depths[2] - 1) + [16],\n",
        "    ]\n",
        "    print(stage_out_channels)\n",
        "\n",
        "    stage_block_types = [\n",
        "        [NTB] * depths[0],\n",
        "        [NCB] * (depths[1] - 1) + [NTB],\n",
        "        [NCB, NTB] * (depths[2] // 1),\n",
        "        #[NCB] * (depths[2] - 1) + [NTB],\n",
        "    ]\n",
        "    print(stage_block_types)'''\n",
        "\n",
        "    stage_out_channels = [\n",
        "        [4] * (depths[0]),\n",
        "        [6] * (depths[1] - 1) + [6],\n",
        "        [8, 16] * (depths[2] // 1),\n",
        "        #[16] * (depths[2] - 1) + [16],\n",
        "    ]\n",
        "    print(stage_out_channels)\n",
        "\n",
        "    stage_block_types = [\n",
        "        [NCB] * depths[0],\n",
        "        [NCB] * (depths[1] - 1) + [NCB],\n",
        "        [NCB, NTB] * (depths[2] // 1),\n",
        "        #[NCB] * (depths[2] - 1) + [NTB],\n",
        "    ]\n",
        "    print(stage_block_types)\n",
        "\n",
        "    input_channel1 = stem_chs[-1]\n",
        "    features1 = []\n",
        "    idx = 0\n",
        "    dpr = [x for x in tf.linspace(0.0, path_dropout, sum(depths))]\n",
        "    for stage_id in range(len(depths)):\n",
        "        numrepeat = depths[stage_id]\n",
        "        output_channels = stage_out_channels[stage_id]\n",
        "        block_types = stage_block_types[stage_id]\n",
        "        for block_id in range(numrepeat):\n",
        "            if strides[stage_id] == 2 and block_id == 0:\n",
        "                stride = 1 #2\n",
        "            else:\n",
        "                stride = 1\n",
        "            output_channel = output_channels[block_id]\n",
        "            print(output_channel)\n",
        "            block_type = block_types[block_id]\n",
        "            print(block_type)\n",
        "            if block_type is NCB:\n",
        "                layer = NCB(\n",
        "                    output_channel,\n",
        "                    strides=stride,\n",
        "                    path_dropout=dpr[idx + block_id],\n",
        "                    drop=0,\n",
        "                    head_dim=2,\n",
        "                )#head_dim=32\n",
        "                features1.append(layer)\n",
        "            elif block_type is NTB:\n",
        "                layer = NTB(\n",
        "                    output_channel,\n",
        "                    path_dropout=dpr[idx + block_id],\n",
        "                    strides=stride,\n",
        "                    sr_ratio=sr_ratios[stage_id],\n",
        "                    head_dim=2,\n",
        "                    mix_block_ratio=0.75,\n",
        "                    attn_drop=0,\n",
        "                    drop=0,\n",
        "                )#head_dim=32\n",
        "                features1.append(layer)\n",
        "        idx += numrepeat\n",
        "    for layer in features1:\n",
        "        x1 = layer(x1)\n",
        "    x1 = layers.BatchNormalization(epsilon=1e-5)(x1)\n",
        "\n",
        "    stem2 = tf.keras.Sequential(\n",
        "        [\n",
        "            ConvBNReLU(stem_chs[0], kernel_size=3, strides=1),  # 2\n",
        "            ConvBNReLU(stem_chs[1], kernel_size=3, strides=1),\n",
        "            # ConvBNReLU(stem_chs[2], kernel_size=3, strides=1),\n",
        "            ConvBNReLU(stem_chs[2], kernel_size=3, strides=1),  # 2\n",
        "        ]\n",
        "    )\n",
        "    x2 = stem2(input_layer2)\n",
        "\n",
        "    input_channel2 = stem_chs[-1]\n",
        "    features2 = []\n",
        "    idx = 0\n",
        "    dpr = [x for x in tf.linspace(0.0, path_dropout, sum(depths))]\n",
        "    for stage_id in range(len(depths)):\n",
        "        numrepeat = depths[stage_id]\n",
        "        output_channels = stage_out_channels[stage_id]\n",
        "        block_types = stage_block_types[stage_id]\n",
        "        for block_id in range(numrepeat):\n",
        "            if strides[stage_id] == 2 and block_id == 0:\n",
        "                stride = 1  # 2\n",
        "            else:\n",
        "                stride = 1\n",
        "            output_channel = output_channels[block_id]\n",
        "            block_type = block_types[block_id]\n",
        "            if block_type is NCB:\n",
        "                layer = NCB(\n",
        "                    output_channel,\n",
        "                    strides=stride,\n",
        "                    path_dropout=dpr[idx + block_id],\n",
        "                    drop=0,\n",
        "                    head_dim=2,\n",
        "                )  # head_dim=32\n",
        "                features2.append(layer)\n",
        "            elif block_type is NTB:\n",
        "                layer = NTB(\n",
        "                    output_channel,\n",
        "                    path_dropout=dpr[idx + block_id],\n",
        "                    strides=stride,\n",
        "                    sr_ratio=sr_ratios[stage_id],\n",
        "                    head_dim=2,\n",
        "                    mix_block_ratio=0.75,\n",
        "                    attn_drop=0,\n",
        "                    drop=0,\n",
        "                )  # head_dim=32\n",
        "                features2.append(layer)\n",
        "        idx += numrepeat\n",
        "    for layer in features2:\n",
        "        x2 = layer(x2)\n",
        "    x2 = layers.BatchNormalization(epsilon=1e-5)(x2)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([x1,x2])\n",
        "\n",
        "    stem = tf.keras.Sequential(\n",
        "        [\n",
        "            ConvBNReLU(stem_chs[0], kernel_size=3, strides=1),  # 2\n",
        "            ConvBNReLU(stem_chs[1], kernel_size=3, strides=1),\n",
        "            # ConvBNReLU(stem_chs[2], kernel_size=3, strides=1),\n",
        "            ConvBNReLU(stem_chs[2], kernel_size=3, strides=1),  # 2\n",
        "        ]\n",
        "    )\n",
        "    x = stem(x)\n",
        "\n",
        "    input_channel = stem_chs[-1]\n",
        "    features = []\n",
        "    idx = 0\n",
        "    dpr = [x for x in tf.linspace(0.0, path_dropout, sum(depths))]\n",
        "    for stage_id in range(len(depths)):\n",
        "        numrepeat = depths[stage_id]\n",
        "        output_channels = stage_out_channels[stage_id]\n",
        "        block_types = stage_block_types[stage_id]\n",
        "        for block_id in range(numrepeat):\n",
        "            if strides[stage_id] == 2 and block_id == 0:\n",
        "                stride = 1  # 2\n",
        "            else:\n",
        "                stride = 1\n",
        "            output_channel = output_channels[block_id]\n",
        "            block_type = block_types[block_id]\n",
        "            if block_type is NCB:\n",
        "                layer = NCB(\n",
        "                    output_channel,\n",
        "                    strides=stride,\n",
        "                    path_dropout=dpr[idx + block_id],\n",
        "                    drop=0,\n",
        "                    head_dim=2,\n",
        "                )  # head_dim=32\n",
        "                features.append(layer)\n",
        "            elif block_type is NTB:\n",
        "                layer = NTB(\n",
        "                    output_channel,\n",
        "                    path_dropout=dpr[idx + block_id],\n",
        "                    strides=stride,\n",
        "                    sr_ratio=sr_ratios[stage_id],\n",
        "                    head_dim=2,\n",
        "                    mix_block_ratio=0.75,\n",
        "                    attn_drop=0,\n",
        "                    drop=0,\n",
        "                )  # head_dim=32\n",
        "                features.append(layer)\n",
        "        idx += numrepeat\n",
        "    for layer in features:\n",
        "        x = layer(x)\n",
        "    x = layers.BatchNormalization(epsilon=1e-5)(x)\n",
        "\n",
        "    x = layers.Conv2D(filters=out_chans, kernel_size=3, strides=1,padding='same')(x)\n",
        "    x = layers.BatchNormalization(epsilon=1e-5)(x)\n",
        "\n",
        "\n",
        "    return keras.Model([input_layer1,input_layer2], x)\n",
        "\n",
        "\n",
        "\n",
        "def nextvit_small_2b(input_shape1=(None, None, 3),input_shape2=(None, None, 3),out_chans=103):\n",
        "    model = NextViT_2b(\n",
        "        input_shape1=input_shape1,\n",
        "        input_shape2=input_shape2,\n",
        "        stem_chs=CONFIG[\"SMALL\"][\"stem_chs\"],\n",
        "        depths=CONFIG[\"SMALL\"][\"depths\"],\n",
        "        path_dropout=CONFIG[\"SMALL\"][\"drop_path\"],\n",
        "        out_chans=out_chans,\n",
        "    )\n",
        "    return model\n",
        "\n",
        "class StochasticDepth(layers.Layer):\n",
        "    \"\"\"Stochastic Depth module.\n",
        "    It is also referred to as Drop Path in `timm`.\n",
        "    References:\n",
        "        (1) github.com:rwightman/pytorch-image-models\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, drop_path, **kwargs):\n",
        "        super(StochasticDepth, self).__init__(**kwargs)\n",
        "        self.drop_path = drop_path\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        if training:\n",
        "            keep_prob = 1 - self.drop_path\n",
        "            shape = (tf.shape(x)[0],) + (1,) * (len(tf.shape(x)) - 1)\n",
        "            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n",
        "            random_tensor = tf.floor(random_tensor)\n",
        "            return (x / keep_prob) * random_tensor\n",
        "        return x\n",
        "\n",
        "\n",
        "# https://github.com/bytedance/Next-ViT/blob/main/classification/nextvit.py\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "class ConvBNReLU(tf.keras.Model):\n",
        "    def __init__(self, filters, kernel_size, strides, groups=1, **kwargs):\n",
        "        super(ConvBNReLU, self).__init__(**kwargs)\n",
        "        self.conv = layers.Conv2D(\n",
        "            filters,\n",
        "            kernel_size=kernel_size,\n",
        "            strides=strides,\n",
        "            groups=groups,\n",
        "            padding=\"SAME\",\n",
        "            use_bias=False,\n",
        "        )\n",
        "        self.norm = layers.BatchNormalization(epsilon=EPSILON)\n",
        "        self.act = tf.keras.layers.ELU()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.act(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MHCA(tf.keras.Model):\n",
        "    def __init__(self, filters, head_dim, **kwargs):\n",
        "        super(MHCA, self).__init__(**kwargs)\n",
        "        self.new = filters // head_dim\n",
        "        self.group_conv3x3 = layers.Conv2D(\n",
        "            filters=filters,\n",
        "            kernel_size=3,\n",
        "            strides=1,\n",
        "            padding=\"same\",\n",
        "            groups=filters // head_dim,\n",
        "            use_bias=False,\n",
        "        )\n",
        "        self.norm = layers.BatchNormalization(epsilon=EPSILON)\n",
        "        self.act = layers.Activation(\"elu\")\n",
        "        self.projection = layers.Conv2D(filters, kernel_size=1, padding=\"same\",use_bias=False)#padding 后加\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.group_conv3x3(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.act(x)\n",
        "        x = self.projection(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class mlp(tf.keras.Model):\n",
        "    def __init__(self, filters, mlp_ratio=1, drop=0.0, **kwargs):\n",
        "        super(mlp, self).__init__(**kwargs)\n",
        "        hidden_dim = _make_divisible(filters * mlp_ratio, 32)\n",
        "        self.conv1 = layers.Conv2D(hidden_dim, kernel_size=1, padding=\"SAME\")#原padding=\"VALID\"\n",
        "        self.act = layers.Activation(\"elu\")\n",
        "        self.drop1 = layers.Dropout(drop)\n",
        "        self.conv2 = layers.Conv2D(filters, kernel_size=1, padding=\"SAME\")#原padding=\"VALID\"\n",
        "        self.drop2 = layers.Dropout(drop)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.drop2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class PatchEmbed(tf.keras.Model):\n",
        "    def __init__(self, filters, strides):\n",
        "        super(PatchEmbed, self).__init__()\n",
        "        self.filters = filters\n",
        "        self.strides = strides\n",
        "\n",
        "        '''if self.strides == 2:\n",
        "            self.avg_pool = tf.keras.layers.AvgPool2D(\n",
        "                pool_size=(2, 2), strides=2, padding=\"same\"\n",
        "            )\n",
        "        else:\n",
        "            self.avg_pool = None'''\n",
        "        self.avg_pool = None\n",
        "\n",
        "        if self.filters is not None:\n",
        "            print(self.filters)\n",
        "            self.conv = tf.keras.layers.Conv2D(\n",
        "                filters=self.filters, kernel_size=1, strides=1, use_bias=False,padding=\"same\"\n",
        "            )#wu padding\n",
        "            self.bn = tf.keras.layers.BatchNormalization(epsilon=EPSILON)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        #if self.avg_pool is not None:\n",
        "        #    x = self.avg_pool(x)\n",
        "        if self.filters is not None:\n",
        "            if x.shape[-1] != self.filters:\n",
        "                #x = tf.keras.layers.Lambda(lambda x: x)(x)\n",
        "                x = x\n",
        "                x = self.conv(x)\n",
        "                x = self.bn(x)\n",
        "            else:\n",
        "                x = x\n",
        "                x = x\n",
        "                x = x\n",
        "                #x = tf.keras.layers.Lambda(lambda x: x)(x)\n",
        "                #x = tf.keras.layers.Lambda(lambda x: x)(x)\n",
        "                #x = tf.keras.layers.Lambda(lambda x: x)(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class NCB(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        filters,\n",
        "        strides=1,\n",
        "        path_dropout=0,\n",
        "        drop=0,\n",
        "        head_dim=2,\n",
        "        mlp_ratio=3,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(NCB, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.strides = strides\n",
        "        self.patch_embed = PatchEmbed(filters, strides)\n",
        "        self.mhca = MHCA(filters, head_dim)\n",
        "        self.attention_path_dropout = StochasticDepth(path_dropout)\n",
        "        self.norm = layers.BatchNormalization(epsilon=EPSILON)\n",
        "        self.mlp = mlp(filters, mlp_ratio=mlp_ratio, drop=drop)\n",
        "        self.mlp_path_dropout = StochasticDepth(path_dropout)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "        x = x + self.attention_path_dropout(self.mhca(x))\n",
        "        x = self.norm(x)\n",
        "        x = x + self.mlp_path_dropout(self.mlp(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class NTB(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        filters,\n",
        "        path_dropout=0,\n",
        "        strides=1,\n",
        "        sr_ratio=1,\n",
        "        mlp_ratio=2,\n",
        "        head_dim=2,\n",
        "        mix_block_ratio=0.75,\n",
        "        attn_drop=0,\n",
        "        drop=0,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(NTB, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.strides = strides\n",
        "        self.mix_block_ratio = mix_block_ratio\n",
        "\n",
        "        self.mhsa_out_channels = _make_divisible(\n",
        "            int(filters * mix_block_ratio), 2\n",
        "        )#,32\n",
        "        print(self.mhsa_out_channels)\n",
        "\n",
        "        self.mhca_out_channels = filters - self.mhsa_out_channels\n",
        "        self.patch_embed = PatchEmbed(self.mhsa_out_channels, strides)\n",
        "        self.norm1 = layers.BatchNormalization(epsilon=EPSILON)\n",
        "        self.e_mhsa = E_MHSA(\n",
        "            self.mhsa_out_channels,\n",
        "            head_dim=head_dim,\n",
        "            sr_ratio=sr_ratio,\n",
        "            attn_drop=attn_drop,\n",
        "            proj_drop=drop,\n",
        "        )\n",
        "        self.mhsa_path_dropout = StochasticDepth(path_dropout * mix_block_ratio)\n",
        "        self.projection = PatchEmbed(self.mhca_out_channels, strides=1)\n",
        "        self.mhca = MHCA(self.mhca_out_channels, head_dim=head_dim)\n",
        "        self.mhca_path_dropout = StochasticDepth(\n",
        "            path_dropout * (1 - mix_block_ratio)\n",
        "        )\n",
        "        self.norm2 = layers.BatchNormalization(epsilon=EPSILON)\n",
        "        self.mlp = mlp(filters, mlp_ratio=mlp_ratio, drop=drop)\n",
        "        self.mlp_path_dropout = StochasticDepth(path_dropout)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "        B, C, H, W = x.shape\n",
        "        out = self.norm1(x)\n",
        "        out = rearrange(out, \"b h w c -> b (h w) c\")\n",
        "        out = self.mhsa_path_dropout(self.e_mhsa(out))\n",
        "        x = x + rearrange(out, \"b (h w) c -> b h w c\", h=H)\n",
        "        out = self.projection(x)\n",
        "        out = out + self.mhca_path_dropout(self.mhca(out))\n",
        "        x = tf.concat([x, out], axis=-1)\n",
        "        out = self.norm2(x)\n",
        "        x = x + self.mlp_path_dropout(self.mlp(out))\n",
        "        return x\n",
        "\n",
        "'''input = Input((256,256,24))\n",
        "test = NTB(128,\n",
        "           path_dropout=0.036363635,\n",
        "           strides=4,\n",
        "           sr_ratio=5,\n",
        "           head_dim=4,\n",
        "           mix_block_ratio=0.75,\n",
        "           attn_drop=0,\n",
        "           drop=0,\n",
        "           )\n",
        "x = test(input)\n",
        "a=1'''\n",
        "\n",
        "\n",
        "\n",
        "class GRID():\n",
        "        # 读图像文件\n",
        "        def read_img(self, filename):\n",
        "            dataset = gdal.Open(filename)\n",
        "            # 打开文件\n",
        "            im_width = dataset.RasterXSize  # 栅格矩阵的列数\n",
        "            im_height = dataset.RasterYSize  # 栅格矩阵的行数\n",
        "\n",
        "            im_geotrans = dataset.GetGeoTransform()  # 仿射矩阵\n",
        "            im_proj = dataset.GetProjection()  # 地图投影信息\n",
        "            im_data = dataset.ReadAsArray(0, 0, im_width, im_height)  # 将数据写成数组，对应栅格矩阵\n",
        "            im_data = np.array(im_data)\n",
        "            sp = im_data.shape\n",
        "            if im_data.ndim == 2:\n",
        "                im_data2 = im_data[:, :, np.newaxis]\n",
        "            else:\n",
        "                im_data2 = np.zeros((im_height, im_width, sp[0]))\n",
        "                for bands in range(0, sp[0]):\n",
        "                    im_data2[:, :, bands] = im_data[bands, :, :]\n",
        "\n",
        "            del dataset\n",
        "            return im_height, im_width, im_data2\n",
        "\n",
        "        def write_img(self, filename, im_proj, im_geotrans, im_data2):\n",
        "            # gdal数据类型包括\n",
        "            # gdal.GDT_Byte,\n",
        "            # gdal .GDT_UInt16, gdal.GDT_Int16, gdal.GDT_UInt32, gdal.GDT_Int32,\n",
        "            # gdal.GDT_Float32, gdal.GDT_Float64\n",
        "            sp = im_data2.shape\n",
        "            if len(sp) > 2:\n",
        "                im_data = np.zeros((sp[2], sp[0], sp[1]))\n",
        "                for bands in range(0, sp[2]):\n",
        "                    im_data[bands, :, :] = im_data2[:, :, bands]\n",
        "                print(im_data.shape)\n",
        "            else:\n",
        "                im_data = im_data2\n",
        "\n",
        "            # 判断栅格数据的数据类型\n",
        "            if 'int8' in im_data.dtype.name:\n",
        "                datatype = gdal.GDT_Byte\n",
        "            elif 'int16' in im_data.dtype.name:\n",
        "                datatype = gdal.GDT_UInt16\n",
        "            else:\n",
        "                datatype = gdal.GDT_Float32\n",
        "\n",
        "            # 判读数组维数\n",
        "            if len(im_data.shape) == 3:\n",
        "                im_bands, im_height, im_width = im_data.shape\n",
        "            else:\n",
        "                im_bands, (im_height, im_width) = 1, im_data.shape\n",
        "\n",
        "            # 创建文件\n",
        "            driver = gdal.GetDriverByName(\"ENVI\")  # 数据类型必须有，因为要计算需要多大内存空间\n",
        "            dataset = driver.Create(filename, im_width, im_height, im_bands, datatype)\n",
        "\n",
        "            #dataset.SetGeoTransform(im_geotrans)  # 写入仿射变换参数\n",
        "            #dataset.SetProjection(im_proj)  # 写入投影\n",
        "\n",
        "            if im_bands == 1:\n",
        "                dataset.GetRasterBand(1).WriteArray(im_data)  # 写入数组数据\n",
        "            else:\n",
        "                for i in range(im_bands):\n",
        "                    dataset.GetRasterBand(i + 1).WriteArray(im_data[i])\n",
        "\n",
        "            del dataset\n",
        "\n",
        "        def restore4d_over(self, data4d, patchsize, sp, jg):\n",
        "\n",
        "            spp = data4d.shape\n",
        "            sm = math.floor((sp[1] - 2 * jg) / (patchsize - 2 * jg))\n",
        "            rex = np.zeros((math.floor(spp[0] / sm) * (patchsize - 2 * jg), sm * (patchsize - 2 * jg), sp[2]))\n",
        "            for ii in range(0, spp[0]):\n",
        "                mm = math.floor(ii / sm)\n",
        "                nn = ii % sm\n",
        "                rex[mm * (patchsize - 2 * jg):(mm + 1) * (patchsize - 2 * jg),\n",
        "                nn * (patchsize - 2 * jg):(nn + 1) * (patchsize - 2 * jg), :] = data4d[ii, jg:patchsize - jg,\n",
        "                                                                                jg:patchsize - jg, :]\n",
        "            return rex\n",
        "\n",
        "        def prepare4d_over(self, img, patchsize, jg):\n",
        "            sp = img.shape\n",
        "            mnum = math.floor((sp[0] - 2 * jg) / (patchsize - 2 * jg))\n",
        "            nnum = math.floor((sp[1] - 2 * jg) / (patchsize - 2 * jg))\n",
        "            result = np.zeros((mnum * nnum, patchsize, patchsize, sp[2]))\n",
        "            count = -1\n",
        "            for i in range(0, mnum):\n",
        "                for j in range(0, nnum):\n",
        "                    count += 1\n",
        "                    result[count, :, :, :] = img[(patchsize - 2 * jg) * i:(patchsize - 2 * jg) * i + patchsize,\n",
        "                                                (patchsize - 2 * jg) * j: (patchsize - 2 * jg) * j + patchsize, :]\n",
        "            return result, sp\n",
        "\n",
        "class ETmodel:\n",
        "    def __init__(self,dirr,patchsize,jg,epochs,resname):\n",
        "        self.patchsize = patchsize\n",
        "        self.jg = jg\n",
        "        self.grid = GRID()\n",
        "        lr_train, vs_train, lr_pred = self.read_data(dirr,patchsize,jg)\n",
        "        print('data read!')\n",
        "        self.model = nextvit_small_2b(input_shape1=(lr_train.shape[1], lr_train.shape[2], 1),\n",
        "                                      input_shape2=(vs_train.shape[1], vs_train.shape[2], 1),\n",
        "                                      out_chans=1\n",
        "                                      )\n",
        "        print('model built!')\n",
        "        plot_model(self.model, to_file='modelvs_auth.png',show_shapes=True)\n",
        "        self.train_model(lr_train, vs_train, lr_pred, epochs)\n",
        "        self.pred_model(dirr,patchsize,jg)\n",
        "        #res = self.grid.restore4d_over(res4d, patchsize, self.sp, jg)\n",
        "        #self.grid.write_img(resname,[],[],res)\n",
        "\n",
        "    def gaussian_down_sample(self,data,w,mask=0):\n",
        "      # masking mode\n",
        "      if np.isscalar(mask):\n",
        "        masking = 0\n",
        "      else:\n",
        "        masking = 1\n",
        "\n",
        "      xdata = data.shape[0]\n",
        "      ydata = data.shape[1]\n",
        "      band = data.shape[2]\n",
        "      hx = int(np.floor(xdata/w))\n",
        "      hy = int(np.floor(ydata/w))\n",
        "      HSI = np.zeros((hx, hy, band))\n",
        "      sig = w/2.35482\n",
        "\n",
        "      if masking == 0: # without mask\n",
        "        if np.mod(w,2)==0:\n",
        "            H1 = self.gaussian_filter2d((w,w),sig).reshape(w,w,1)\n",
        "            H2 = self.gaussian_filter2d((w*2,w*2),sig).reshape(w*2,w*2,1)\n",
        "            for x in range(hx):\n",
        "                for y in range(hy):\n",
        "                    if x==0 or x==hx-1 or y==0 or y==hy-1:\n",
        "                        HSI[x,y,:] = (np.double( data[x*w:(x+1)*w,y*w:(y+1)*w,:] ) * np.tile(H1,(1,1,band))).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "                    else:\n",
        "                        HSI[x,y,:] = (np.double( data[x*w-int(w/2):(x+1)*w+int(w/2),y*w-int(w/2):(y+1)*w+int(w/2),:] ) * np.tile(H2,(1,1,band))).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "        else:\n",
        "            H1 = self.gaussian_filter2d((w,w),sig).reshape(w,w,1)\n",
        "            H2 = self.gaussian_filter2d((w*2-1,w*2-1),sig).reshape(w*2-1,w*2-1,1)\n",
        "            for x in range(hx):\n",
        "                for y in range(hy):\n",
        "                    if x==0 or x==hx-1 or y==0 or y==hy-1:\n",
        "                        HSI[x,y,:] = (np.double( data[x*w:(x+1)*w,y*w:(y+1)*w,:] ) * np.tile(H1,(1,1,band)) ).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "                    else:\n",
        "                        HSI[x,y,:] = (np.double( data[x*w-int((w-1)/2):(x+1)*w+int((w-1)/2),y*w-int((w-1)/2):(y+1)*w+int((w-1)/2),:] ) * np.tile(H2,(1,1,band))).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "      else: # with mask\n",
        "        if np.mod(w,2)==0:\n",
        "            H1 = self.gaussian_filter2d((w,w),sig).reshape(w,w,1)\n",
        "            H2 = self.gaussian_filter2d((w*2,w*2),sig).reshape(w*2,w*2,1)\n",
        "            for x in range(hx):\n",
        "                for y in range(hy):\n",
        "                    mask_tmp = mask[x*w:(x+1)*w,y*w:(y+1)*w]\n",
        "                    if mask_tmp.sum() == w**2:\n",
        "                        if x==0 or x==hx-1 or y==0 or y==hy-1:\n",
        "                            HSI[x,y,:] = (np.double( data[x*w:(x+1)*w,y*w:(y+1)*w,:] ) * np.tile(H1,(1,1,band))).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "                        else:\n",
        "                            HSI[x,y,:] = (np.double( data[x*w-int(w/2):(x+1)*w+int(w/2),y*w-int(w/2):(y+1)*w+int(w/2),:] ) * np.tile(H2,(1,1,band))).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "        else:\n",
        "            H1 = self.gaussian_filter2d((w,w),sig).reshape(w,w,1)\n",
        "            H2 = self.gaussian_filter2d((w*2-1,w*2-1),sig).reshape(w*2-1,w*2-1,1)\n",
        "            for x in range(hx):\n",
        "                for y in range(hy):\n",
        "                    mask_tmp = mask[x*w:(x+1)*w,y*w:(y+1)*w]\n",
        "                    if mask_tmp.sum() == w**2:\n",
        "                        if x==0 or x==hx-1 or y==0 or y==hy-1:\n",
        "                            HSI[x,y,:] = (np.double( data[x*w:(x+1)*w,y*w:(y+1)*w,:] ) * np.tile(H1,(1,1,band)) ).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "                        else:\n",
        "                            HSI[x,y,:] = (np.double( data[x*w-int((w-1)/2):(x+1)*w+int((w-1)/2),y*w-int((w-1)/2):(y+1)*w+int((w-1)/2),:] ) * np.tile(H2,(1,1,band))).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "\n",
        "      return HSI\n",
        "\n",
        "    def gaussian_filter2d(self,shape=(3,3),sigma=1):\n",
        "      m,n = [(ss-1.)/2. for ss in shape]\n",
        "      y,x = np.ogrid[-m:m+1,-n:n+1]\n",
        "      h = np.exp( -(x**2 + y**2) / (2.*sigma**2) )\n",
        "      h[ h < np.finfo(h.dtype).eps*h.max() ] = 0\n",
        "      sumh = h.sum()\n",
        "      if sumh != 0:\n",
        "        h /= sumh\n",
        "      return h\n",
        "\n",
        "    def read_data(self,dirr,patchsize,jg):\n",
        "        lrdata = []\n",
        "        vsdata = []\n",
        "        zdlr = {}\n",
        "        zdvs = {}\n",
        "        lr_train = []\n",
        "        vs_train = []\n",
        "        lr_pred = []\n",
        "        lr_tar = []\n",
        "        dirl = dirr + r'/lr'\n",
        "        dirv = dirr + r'/vis2pan'\n",
        "        listl = os.listdir(dirl)\n",
        "        listv = os.listdir(dirv)\n",
        "        nums = len(dirl)\n",
        "        indd = np.arange(nums)[0:60]\n",
        "        random.shuffle(indd)\n",
        "        listl = [listl[i] for i in indd]\n",
        "        listv = [listv[i] for i in indd]\n",
        "\n",
        "        for ii in range(0,len(listl)):\n",
        "          lfile = listl[ii]\n",
        "          lfile = dirl + r'/' + lfile\n",
        "          imgr = cv2.imread(lfile,0)\n",
        "          gauss = np.random.normal(0,25,(imgr.shape[0],imgr.shape[1]))\n",
        "          imgr = imgr + gauss\n",
        "\n",
        "          vfile = listv[ii]\n",
        "          vfile = dirv + r'/' + vfile\n",
        "          imgv = cv2.imread(vfile,0)\n",
        "\n",
        "\n",
        "          if imgr.shape != imgv.shape:\n",
        "            sp = [min(imgr.shape[0],imgv.shape[0]),min(imgr.shape[1],imgv.shape[1])]\n",
        "            imgr = imgr[:sp[0],:sp[1]]\n",
        "            imgv = imgv[:sp[0],:sp[1]]\n",
        "\n",
        "          imgr = imgr[:,:,np.newaxis]\n",
        "          imgv = imgv[:,:,np.newaxis]\n",
        "\n",
        "          #lr_train\n",
        "          imgr1 = cv2.resize(cv2.resize(imgr,\n",
        "           (int(imgr.shape[0]/9*4),int(imgr.shape[1]/9*4))),(int(imgr.shape[0]/3*2),int(imgr.shape[1]/3*2)))[:,:,np.newaxis]\n",
        "          #lr_pred\n",
        "          imgr2 = cv2.resize(imgr,(int(imgr.shape[0]/3*2),int(imgr.shape[1]/3*2)))[:,:,np.newaxis]\n",
        "\n",
        "\n",
        "          #vs_train\n",
        "          imgv1 = cv2.resize(imgv,(int(imgv.shape[0]/3*2),int(imgv.shape[1]/3*2)))[:,:,np.newaxis]\n",
        "\n",
        "\n",
        "          if lr_train == []:\n",
        "            lr_train,sp = self.grid.prepare4d_over(imgr1,patchsize,jg)\n",
        "          else:\n",
        "            temp,sp = self.grid.prepare4d_over(imgr1,patchsize,jg)\n",
        "            lr_train = np.concatenate((lr_train,temp),axis=0)\n",
        "\n",
        "          if lr_pred == []:\n",
        "            lr_pred,sp = self.grid.prepare4d_over(imgr2,patchsize,jg)\n",
        "          else:\n",
        "            temp,sp = self.grid.prepare4d_over(imgr2,patchsize,jg)\n",
        "            lr_pred = np.concatenate((lr_pred,temp),axis=0)\n",
        "\n",
        "\n",
        "          if vs_train == []:\n",
        "            vs_train,sp = self.grid.prepare4d_over(imgv1,patchsize,jg)\n",
        "          else:\n",
        "            temp,sp = self.grid.prepare4d_over(imgv1,patchsize,jg)\n",
        "            vs_train = np.concatenate((vs_train,temp),axis=0)\n",
        "\n",
        "        print(lr_train.shape)\n",
        "        print(vs_train.shape)\n",
        "        print(lr_pred.shape)\n",
        "\n",
        "        indd = np.arange(0,lr_train.shape[0])\n",
        "        np.random.shuffle(indd)\n",
        "        lr_train = lr_train[indd,:,:,:]\n",
        "        vs_train = vs_train[indd,:,:,:]\n",
        "        lr_pred = lr_pred[indd,:,:,:]\n",
        "\n",
        "        return lr_train, vs_train, lr_pred\n",
        "\n",
        "    def train_model(self,x1,x2,y,epochs):\n",
        "        print(x1.shape)\n",
        "        print(x2.shape)\n",
        "        print(y.shape)\n",
        "        minn = min(x1.shape[0],x2.shape[0])\n",
        "        optim = tf.keras.optimizers.Adam(lr=0.001)\n",
        "        self.model.compile(loss='mse', optimizer=optim, metrics=['accuracy'])\n",
        "        if os.path.isfile('pres_model.h5'):\n",
        "            self.model.load_weights('pres_model.h5')\n",
        "            self.status = 1\n",
        "            # return\n",
        "        else:\n",
        "            callbacks1 = EarlyStopping(monitor='loss', min_delta=0, patience=15, verbose=0, mode='auto',\n",
        "                                       baseline=None, restore_best_weights=True)\n",
        "            reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                                          patience=7, min_lr=0.00001)\n",
        "            # history = self.p_model.fit(x=self.hd5mu[:,np.linspace(0,8,5,dtype='int8'),:,:,:], y=self.hd5l, batch_size=32, callbacks = [callbacks1,reduce_lr],epochs=self.epochs, validation_split=0.1)\n",
        "            history = self.model.fit(x=[x1[:minn,:,:,:]/100,x2[:minn,:,:,:]/100], y=y/100, batch_size=4,\n",
        "                                       callbacks=[callbacks1, reduce_lr],\n",
        "                                       epochs=epochs, validation_split=0.1)\n",
        "            #history = self.model.fit_generator(self.datagen.flow([x1[:minn,:,:,:]/1000,x2[:minn,:,:,:]/1000],\n",
        "            #                                           y=y[:minn,:,:,:]/1000),\n",
        "            #                                           epochs=epochs,\n",
        "            #                                           steps_per_epoch=minn/4)\n",
        "            self.model.save_weights('pres_model.h5')\n",
        "            loss_history = history.history[\"loss\"]\n",
        "            val_loss_history = history.history['val_loss']\n",
        "            numpy_loss_history = np.array(loss_history)\n",
        "            numpy_val_loss = np.array(val_loss_history)\n",
        "            np.savetxt('pres_loss.txt', numpy_loss_history,delimiter=\",\")\n",
        "            np.savetxt('pres_val_loss.txt', numpy_val_loss,delimiter=\",\")\n",
        "\n",
        "    def pred_model(self,dirr,patchsize,jg):\n",
        "        dirl = dirr + r'/lr'\n",
        "        dirv = dirr + r'/vis2pan'\n",
        "        dirres = dirr + r'/res/'\n",
        "        listl = os.listdir(dirl)\n",
        "        listv = os.listdir(dirv)\n",
        "        for ii in range(0,len(listl)):\n",
        "          lfile = listl[ii]\n",
        "          lfile = dirl + r'/' + lfile\n",
        "          imgr = cv2.imread(lfile,0)\n",
        "\n",
        "          vfile = listv[ii]\n",
        "          vfile = dirv + r'/' + vfile\n",
        "          imgv = cv2.imread(vfile,0)\n",
        "\n",
        "          if imgr.shape != imgv.shape:\n",
        "            sp = [min(imgr.shape[0],imgv.shape[0]),min(imgr.shape[1],imgv.shape[1])]\n",
        "            imgr = imgr[:sp[0],:sp[1]]\n",
        "            imgv = imgv[:sp[0],:sp[1]]\n",
        "\n",
        "          imgr = imgr[:,:,np.newaxis]\n",
        "          imgv = imgv[:,:,np.newaxis]\n",
        "\n",
        "          imgr2 = cv2.resize(imgr,(int(imgv.shape[1]/3*2),int(imgv.shape[0]/3*2)))[:,:,np.newaxis]\n",
        "          #lr_tar\n",
        "          imgr3 = cv2.resize(imgr2,(imgv.shape[1],imgv.shape[0]))[:,:,np.newaxis]\n",
        "\n",
        "          lr_tar,sp = self.grid.prepare4d_over(imgr3,patchsize,5)\n",
        "          vsdata,sp = self.grid.prepare4d_over(imgv,patchsize,5)\n",
        "\n",
        "          print(lr_tar.shape)\n",
        "          print(vsdata.shape)\n",
        "\n",
        "          res4d = self.model.predict([lr_tar/100,vsdata/100], batch_size=8)*100\n",
        "          res = self.grid.restore4d_over(res4d,patchsize,sp,5)\n",
        "          cv2.imwrite(dirres + listl[ii][:-4]+'_fus.png', np.array(np.squeeze(res),dtype=int))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    dirr = r'/content/drive/MyDrive/new'\n",
        "    os.chdir(dirr)\n",
        "    print(os.getcwd())\n",
        "    print(os.listdir())\n",
        "    patchsize = 64\n",
        "    jg = 0\n",
        "    epochs = 1000\n",
        "\n",
        "    starttime = datetime.datetime.now()\n",
        "    ET = ETmodel(dirr,patchsize,jg,epochs,'')\n",
        "    endtime = datetime.datetime.now()\n",
        "    print('total time is ' + str(endtime - starttime) + 's')\n",
        "    np.savetxt('time_cst.txt', np.array([(endtime - starttime).seconds]), delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhMjJ8vOPOpg",
        "outputId": "e8d9622d-399d-4b53-c199-f3738791983c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "psmisc is already the newest version (23.4-2build3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "/dev/nvidia0:          228m\n",
            "/dev/nvidiactl:        228m\n",
            "/dev/nvidia-uvm:       228m\n"
          ]
        }
      ],
      "source": [
        "!apt install psmisc\n",
        "!sudo fuser /dev/nvidia*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3wfGKigPUnx"
      },
      "outputs": [],
      "source": [
        "!kill -9 228"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "vit 2loss 思路"
      ],
      "metadata": {
        "id": "TUpu-CcGq53r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "import keras.backend as K\n",
        "from einops import rearrange\n",
        "from keras.layers import Input\n",
        "from typing import List, Union\n",
        "import os\n",
        "from osgeo import gdal\n",
        "import numpy as np\n",
        "import math\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.utils import plot_model\n",
        "import datetime\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "\n",
        "EPSILON = 1e-5\n",
        "\n",
        "\n",
        "CONFIG = {\n",
        "    \"SMALL\": {\n",
        "        \"stem_chs\": [32,16,32],\n",
        "        \"depths\": [1,2],\n",
        "        \"drop_path\": 0.1,\n",
        "    },\n",
        "    \"BASE\": {\n",
        "        \"stem_chs\": [64, 32, 64],\n",
        "        \"depths\": [3, 4, 20, 3],\n",
        "        \"drop_path\": 0.1,\n",
        "    },\n",
        "    \"LARGE\": {\n",
        "        \"stem_chs\": [64, 32, 64],\n",
        "        \"depths\": [3, 4, 30, 3],\n",
        "        \"drop_path\": 0.1,\n",
        "    },\n",
        "}\n",
        "#\"SMALL\": {\n",
        "#        \"stem_chs\": [64, 32, 64],\n",
        "#        \"depths\": [3, 4, 10, 3],\n",
        "#        \"drop_path\": 0.1,\n",
        "#    },\n",
        "# https://github.com/huggingface/transformers/blob/60d51ef5123d949fd8c59cd4d3254e711541d278/src/transformers/tf_utils.py#L26\n",
        "def shape_list(tensor: Union[tf.Tensor, np.ndarray]) -> List[int]:\n",
        "    if isinstance(tensor, np.ndarray):\n",
        "        return list(tensor.shape)\n",
        "    dynamic = tf.shape(tensor)\n",
        "    if tensor.shape == tf.TensorShape(None):\n",
        "        return dynamic\n",
        "    static = tensor.shape.as_list()\n",
        "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
        "\n",
        "\n",
        "class E_MHSA(layers.Layer):\n",
        "    \"\"\"\n",
        "    Efficient Multi-Head Self Attention\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        out_dim=None,\n",
        "        head_dim=2,\n",
        "        qkv_bias=True,\n",
        "        qk_scale=None,\n",
        "        attn_drop=0,\n",
        "        proj_drop=0.0,\n",
        "        sr_ratio=1,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.out_dim = out_dim if out_dim is not None else dim\n",
        "        self.num_heads = self.dim // head_dim\n",
        "        self.scale = qk_scale or head_dim**-0.5\n",
        "        self.q = tf.keras.layers.Dense(dim, use_bias=qkv_bias)\n",
        "        self.k = tf.keras.layers.Dense(dim, use_bias=qkv_bias)\n",
        "        self.v = tf.keras.layers.Dense(dim, use_bias=qkv_bias)\n",
        "        self.proj = tf.keras.layers.Dense(self.out_dim)\n",
        "        self.attn_drop = tf.keras.layers.Dropout(attn_drop)\n",
        "        self.proj_drop = tf.keras.layers.Dropout(proj_drop)\n",
        "\n",
        "        self.sr_ratio = sr_ratio\n",
        "        self.N_ratio = sr_ratio**2\n",
        "        if sr_ratio > 1:\n",
        "            self.sr = tf.keras.layers.AveragePooling1D(\n",
        "                pool_size=self.N_ratio, strides=self.N_ratio\n",
        "            )\n",
        "            self.norm = tf.keras.layers.BatchNormalization(epsilon=1e-5)\n",
        "\n",
        "    def call(self, x):\n",
        "        B = shape_list(x)[0]\n",
        "        N = shape_list(x)[1]\n",
        "        C = shape_list(x)[2]\n",
        "        q = self.q(x)\n",
        "        q = tf.reshape(q, (B, N, self.num_heads, int(C // self.num_heads)))\n",
        "        q = tf.transpose(q, perm=[0, 2, 1, 3])\n",
        "\n",
        "        if self.sr_ratio > 1:\n",
        "            x_ = tf.transpose(x, perm=[0, 2, 1])\n",
        "            #x_ = self.sr(x_)\n",
        "            x_ = tf.transpose(x_, perm=[0, 2, 1])\n",
        "            k = self.k(x_)\n",
        "            k = tf.reshape(k, (B, -1, self.num_heads, C // self.num_heads))\n",
        "            k = tf.transpose(k, perm=[0, 2, 3, 1])\n",
        "            v = self.v(x_)\n",
        "            v = tf.reshape(v, (B, -1, self.num_heads, C // self.num_heads))\n",
        "            v = tf.transpose(v, perm=[0, 2, 1, 3])\n",
        "        else:\n",
        "            k = self.k(x)\n",
        "            k = tf.reshape(k, (B, -1, self.num_heads, C // self.num_heads))\n",
        "            k = tf.transpose(k, perm=[0, 2, 3, 1])\n",
        "            v = self.v(x)\n",
        "            v = tf.reshape(v, (B, -1, self.num_heads, C // self.num_heads))\n",
        "            v = tf.transpose(v, perm=[0, 2, 1, 3])\n",
        "        attn = tf.matmul(q, k) * self.scale\n",
        "\n",
        "        #attn = tf.nn.softmax(attn, axis=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = tf.matmul(attn, v)\n",
        "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "        x = tf.reshape(x, (B, N, C))\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def Encoder(\n",
        "    input_shape1, stem_chs, depths, path_dropout,out_chans,\n",
        ") -> keras.Model:\n",
        "    strides = [1, 1, 1] #[1, 2, 2, 2]\n",
        "    sr_ratios = [4, 2, 1]\n",
        "    input_layer1 = layers.Input(input_shape1)\n",
        "    #input_layer2 = layers.Input(input_shape2)\n",
        "    #input_layer1 = layers.Input((256,256,32))\n",
        "    #input_layer2 = layers.Input((256,256,14))\n",
        "\n",
        "    stem1 = tf.keras.Sequential(\n",
        "        [\n",
        "            ConvBNReLU(stem_chs[0], kernel_size=3, strides=1),#2\n",
        "            ConvBNReLU(stem_chs[1], kernel_size=3, strides=1),\n",
        "            #ConvBNReLU(stem_chs[2], kernel_size=3, strides=1),\n",
        "            ConvBNReLU(stem_chs[2], kernel_size=3, strides=1),#2\n",
        "        ]\n",
        "    )\n",
        "    x1 = stem1(input_layer1)\n",
        "\n",
        "    '''stage_out_channels = [\n",
        "        [4] * (depths[0]),\n",
        "        [8] * (depths[1] - 1) + [8],\n",
        "        [16, 32] * (depths[2] // 1),\n",
        "        #[16] * (depths[2] - 1) + [16],\n",
        "    ]\n",
        "    print(stage_out_channels)\n",
        "\n",
        "    stage_block_types = [\n",
        "        [NTB] * depths[0],\n",
        "        [NCB] * (depths[1] - 1) + [NTB],\n",
        "        [NCB, NTB] * (depths[2] // 1),\n",
        "        #[NCB] * (depths[2] - 1) + [NTB],\n",
        "    ]\n",
        "    print(stage_block_types)'''\n",
        "\n",
        "    stage_out_channels = [\n",
        "        [4] * (depths[0]),\n",
        "        #[6] * (depths[1] - 1) + [6],\n",
        "        [8, 16] * (depths[1] // 1),\n",
        "        #[16] * (depths[2] - 1) + [16],\n",
        "    ]\n",
        "\n",
        "    stage_block_types = [\n",
        "        [NCB] * depths[0],\n",
        "        #[NCB] * (depths[1] - 1) + [NCB],\n",
        "        [NCB, NTB] * (depths[1] // 1),\n",
        "        #[NCB] * (depths[2] - 1) + [NTB],\n",
        "    ]\n",
        "\n",
        "    input_channel1 = stem_chs[-1]\n",
        "    features1 = []\n",
        "    idx = 0\n",
        "    dpr = [x for x in tf.linspace(0.0, path_dropout, sum(depths))]\n",
        "    for stage_id in range(len(depths)):\n",
        "        numrepeat = depths[stage_id]\n",
        "        output_channels = stage_out_channels[stage_id]\n",
        "        block_types = stage_block_types[stage_id]\n",
        "        for block_id in range(numrepeat):\n",
        "            if strides[stage_id] == 2 and block_id == 0:\n",
        "                stride = 1 #2\n",
        "            else:\n",
        "                stride = 1\n",
        "            output_channel = output_channels[block_id]\n",
        "            block_type = block_types[block_id]\n",
        "            if block_type is NCB:\n",
        "                layer = NCB(\n",
        "                    output_channel,\n",
        "                    strides=stride,\n",
        "                    path_dropout=dpr[idx + block_id],\n",
        "                    drop=0,\n",
        "                    head_dim=2,\n",
        "                )#head_dim=32\n",
        "                features1.append(layer)\n",
        "            elif block_type is NTB:\n",
        "                layer = NTB(\n",
        "                    output_channel,\n",
        "                    path_dropout=dpr[idx + block_id],\n",
        "                    strides=stride,\n",
        "                    sr_ratio=sr_ratios[stage_id],\n",
        "                    head_dim=2,\n",
        "                    mix_block_ratio=0.75,\n",
        "                    attn_drop=0,\n",
        "                    drop=0,\n",
        "                )#head_dim=32\n",
        "                features1.append(layer)\n",
        "        idx += numrepeat\n",
        "    for layer in features1:\n",
        "        x1 = layer(x1)\n",
        "    x1 = layers.BatchNormalization(epsilon=1e-5)(x1)\n",
        "    sp = x1.shape\n",
        "    x1 = layers.Flatten()(x1)\n",
        "    z_mean = layers.Dense(out_chans, name=\"z_mean\")(x1)\n",
        "    z_log_var = layers.Dense(out_chans, name=\"z_log_var\")(x1)\n",
        "    return keras.Model(input_layer1, [z_mean,z_log_var])\n",
        "\n",
        "def Decoder(\n",
        "    input_shape1,stem_chs, depths, path_dropout,out_chans,patchsize,\n",
        ") -> keras.Model:\n",
        "\n",
        "    strides = [1, 1, 1] #[1, 2, 2, 2]\n",
        "    sr_ratios = [1, 2, 4]\n",
        "    d1,d2 = depths\n",
        "    depths = [d2,d1]\n",
        "    input_layer1 = layers.Input(input_shape1,name='decoder_input')\n",
        "    #input_layer2 = layers.Input(input_shape2)\n",
        "    #input_layer1 = layers.Input((256,256,32))\n",
        "    #input_layer2 = layers.Input((256,256,14))\n",
        "\n",
        "    x1 = layers.Dense(patchsize*patchsize*64)(input_layer1)\n",
        "\n",
        "    x1 = layers.Reshape((patchsize, patchsize, 64))(x1)\n",
        "\n",
        "    stage_out_channels = [[8, 16] * (depths[0] // 1),\n",
        "        [4] * (depths[1])]\n",
        "\n",
        "    stage_block_types = [\n",
        "        [NTB, NCB] * (depths[0] // 1),\n",
        "        [NCB] * depths[1]]\n",
        "\n",
        "    input_channel1 = stem_chs[-1]\n",
        "    features1 = []\n",
        "    idx = 0\n",
        "    dpr = [x for x in tf.linspace(0.0, path_dropout, sum(depths))]\n",
        "    for stage_id in range(len(depths)):\n",
        "        numrepeat = depths[stage_id]\n",
        "        output_channels = stage_out_channels[stage_id]\n",
        "        block_types = stage_block_types[stage_id]\n",
        "        for block_id in range(numrepeat):\n",
        "            if strides[stage_id] == 2 and block_id == 0:\n",
        "                stride = 1 #2\n",
        "            else:\n",
        "                stride = 1\n",
        "            output_channel = output_channels[block_id]\n",
        "            block_type = block_types[block_id]\n",
        "            if block_type is NCB:\n",
        "                layer = NCB(\n",
        "                    output_channel,\n",
        "                    strides=stride,\n",
        "                    path_dropout=dpr[idx + block_id],\n",
        "                    drop=0,\n",
        "                    head_dim=2)#head_dim=32\n",
        "                features1.append(layer)\n",
        "            elif block_type is NTB:\n",
        "                layer = NTB(\n",
        "                    output_channel,\n",
        "                    path_dropout=dpr[idx + block_id],\n",
        "                    strides=stride,\n",
        "                    sr_ratio=sr_ratios[stage_id],\n",
        "                    head_dim=2,\n",
        "                    mix_block_ratio=0.75,\n",
        "                    attn_drop=0,\n",
        "                    drop=0)#head_dim=32\n",
        "                features1.append(layer)\n",
        "        idx += numrepeat\n",
        "    for layer in features1:\n",
        "        x1 = layer(x1)\n",
        "\n",
        "    stem1 = tf.keras.Sequential(\n",
        "        [\n",
        "            ConvBNReLU(stem_chs[2], kernel_size=3, strides=1),#2\n",
        "            ConvBNReLU(stem_chs[1], kernel_size=3, strides=1),\n",
        "            #ConvBNReLU(stem_chs[2], kernel_size=3, strides=1),\n",
        "            ConvBNReLU(out_chans, kernel_size=3, strides=1)])\n",
        "    x1 = stem1(x1)\n",
        "\n",
        "\n",
        "    x1 = layers.BatchNormalization(epsilon=1e-5,name='decoder_output')(x1)\n",
        "\n",
        "\n",
        "    return keras.Model(input_layer1, x1)\n",
        "\n",
        "\n",
        "def autoencoder(input_shape1=(None, None, 3),latent_dim=1024,out_chans=1,patchsize=64):\n",
        "    en_model = Encoder(\n",
        "        input_shape1=input_shape1,\n",
        "        stem_chs=CONFIG[\"SMALL\"][\"stem_chs\"],\n",
        "        depths=CONFIG[\"SMALL\"][\"depths\"],\n",
        "        path_dropout=CONFIG[\"SMALL\"][\"drop_path\"],\n",
        "        out_chans=latent_dim)\n",
        "    de_model = Decoder(\n",
        "        input_shape1=(None,latent_dim),\n",
        "        stem_chs=CONFIG[\"SMALL\"][\"stem_chs\"],\n",
        "        depths=CONFIG[\"SMALL\"][\"depths\"],\n",
        "        path_dropout=CONFIG[\"SMALL\"][\"drop_path\"],\n",
        "        out_chans=out_chans,patchsize=patchsize)\n",
        "    return en_model, de_model\n",
        "\n",
        "\n",
        "def nextvit_small_2b(input_shape1=(None, None, 3),input_shape2=(None, None, 3),out_chans=103,patchsize=64):\n",
        "    vau_e, vau_d = autoencoder(input_shape1=input_shape1,latent_dim=64,out_chans=1,patchsize=64)\n",
        "    iau_e, iau_d = autoencoder(input_shape1=input_shape2,latent_dim=64,out_chans=1,patchsize=64)\n",
        "    return vau_e, vau_d, iau_e, iau_d\n",
        "\n",
        "class StochasticDepth(layers.Layer):\n",
        "    \"\"\"Stochastic Depth module.\n",
        "    It is also referred to as Drop Path in `timm`.\n",
        "    References:\n",
        "        (1) github.com:rwightman/pytorch-image-models\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, drop_path, **kwargs):\n",
        "        super(StochasticDepth, self).__init__(**kwargs)\n",
        "        self.drop_path = drop_path\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        if training:\n",
        "            keep_prob = 1 - self.drop_path\n",
        "            shape = (tf.shape(x)[0],) + (1,) * (len(tf.shape(x)) - 1)\n",
        "            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n",
        "            random_tensor = tf.floor(random_tensor)\n",
        "            return (x / keep_prob) * random_tensor\n",
        "        return x\n",
        "\n",
        "\n",
        "# https://github.com/bytedance/Next-ViT/blob/main/classification/nextvit.py\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "class ConvBNReLU(tf.keras.Model):\n",
        "    def __init__(self, filters, kernel_size, strides, groups=1, **kwargs):\n",
        "        super(ConvBNReLU, self).__init__(**kwargs)\n",
        "        self.conv = layers.Conv2D(\n",
        "            filters,\n",
        "            kernel_size=kernel_size,\n",
        "            strides=strides,\n",
        "            groups=groups,\n",
        "            padding=\"SAME\",\n",
        "            use_bias=False,\n",
        "        )\n",
        "        self.norm = layers.BatchNormalization(epsilon=EPSILON)\n",
        "        self.act = tf.keras.layers.ELU()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.act(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MHCA(tf.keras.Model):\n",
        "    def __init__(self, filters, head_dim, **kwargs):\n",
        "        super(MHCA, self).__init__(**kwargs)\n",
        "        self.new = filters // head_dim\n",
        "        self.group_conv3x3 = layers.Conv2D(\n",
        "            filters=filters,\n",
        "            kernel_size=3,\n",
        "            strides=1,\n",
        "            padding=\"same\",\n",
        "            groups=filters // head_dim,\n",
        "            use_bias=False,\n",
        "        )\n",
        "        self.norm = layers.BatchNormalization(epsilon=EPSILON)\n",
        "        self.act = layers.Activation(\"elu\")\n",
        "        self.projection = layers.Conv2D(filters, kernel_size=1, padding=\"same\",use_bias=False)#padding 后加\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.group_conv3x3(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.act(x)\n",
        "        x = self.projection(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class mlp(tf.keras.Model):\n",
        "    def __init__(self, filters, mlp_ratio=1, drop=0.0, **kwargs):\n",
        "        super(mlp, self).__init__(**kwargs)\n",
        "        hidden_dim = _make_divisible(filters * mlp_ratio, 32)\n",
        "        self.conv1 = layers.Conv2D(hidden_dim, kernel_size=1, padding=\"SAME\")#原padding=\"VALID\"\n",
        "        self.act = layers.Activation(\"elu\")\n",
        "        self.drop1 = layers.Dropout(drop)\n",
        "        self.conv2 = layers.Conv2D(filters, kernel_size=1, padding=\"SAME\")#原padding=\"VALID\"\n",
        "        self.drop2 = layers.Dropout(drop)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.drop2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class PatchEmbed(tf.keras.Model):\n",
        "    def __init__(self, filters, strides):\n",
        "        super(PatchEmbed, self).__init__()\n",
        "        self.filters = filters\n",
        "        self.strides = strides\n",
        "\n",
        "        '''if self.strides == 2:\n",
        "            self.avg_pool = tf.keras.layers.AvgPool2D(\n",
        "                pool_size=(2, 2), strides=2, padding=\"same\"\n",
        "            )\n",
        "        else:\n",
        "            self.avg_pool = None'''\n",
        "        self.avg_pool = None\n",
        "\n",
        "        if self.filters is not None:\n",
        "            self.conv = tf.keras.layers.Conv2D(\n",
        "                filters=self.filters, kernel_size=1, strides=1, use_bias=False,padding=\"same\")#wu padding\n",
        "            self.bn = tf.keras.layers.BatchNormalization(epsilon=EPSILON)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        #if self.avg_pool is not None:\n",
        "        #    x = self.avg_pool(x)\n",
        "        if self.filters is not None:\n",
        "            if x.shape[-1] != self.filters:\n",
        "                #x = tf.keras.layers.Lambda(lambda x: x)(x)\n",
        "                x = x\n",
        "                x = self.conv(x)\n",
        "                x = self.bn(x)\n",
        "            else:\n",
        "                x = x\n",
        "                x = x\n",
        "                x = x\n",
        "                #x = tf.keras.layers.Lambda(lambda x: x)(x)\n",
        "                #x = tf.keras.layers.Lambda(lambda x: x)(x)\n",
        "                #x = tf.keras.layers.Lambda(lambda x: x)(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class NCB(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        filters,\n",
        "        strides=1,\n",
        "        path_dropout=0,\n",
        "        drop=0,\n",
        "        head_dim=2,\n",
        "        mlp_ratio=3,\n",
        "        **kwargs):\n",
        "        super(NCB, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.strides = strides\n",
        "        self.patch_embed = PatchEmbed(filters, strides)\n",
        "        self.mhca = MHCA(filters, head_dim)\n",
        "        self.attention_path_dropout = StochasticDepth(path_dropout)\n",
        "        self.norm = layers.BatchNormalization(epsilon=EPSILON)\n",
        "        self.mlp = mlp(filters, mlp_ratio=mlp_ratio, drop=drop)\n",
        "        self.mlp_path_dropout = StochasticDepth(path_dropout)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "        x = x + self.attention_path_dropout(self.mhca(x))\n",
        "        x = self.norm(x)\n",
        "        x = x + self.mlp_path_dropout(self.mlp(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class NTB(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        filters,\n",
        "        path_dropout=0,\n",
        "        strides=1,\n",
        "        sr_ratio=1,\n",
        "        mlp_ratio=2,\n",
        "        head_dim=2,\n",
        "        mix_block_ratio=0.75,\n",
        "        attn_drop=0,\n",
        "        drop=0,\n",
        "        **kwargs):\n",
        "        super(NTB, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.strides = strides\n",
        "        self.mix_block_ratio = mix_block_ratio\n",
        "\n",
        "        self.mhsa_out_channels = _make_divisible(\n",
        "            int(filters * mix_block_ratio), 2)#,32\n",
        "\n",
        "        self.mhca_out_channels = filters - self.mhsa_out_channels\n",
        "        self.patch_embed = PatchEmbed(self.mhsa_out_channels, strides)\n",
        "        self.norm1 = layers.BatchNormalization(epsilon=EPSILON)\n",
        "        self.e_mhsa = E_MHSA(\n",
        "            self.mhsa_out_channels,\n",
        "            head_dim=head_dim,\n",
        "            sr_ratio=sr_ratio,\n",
        "            attn_drop=attn_drop,\n",
        "            proj_drop=drop)\n",
        "        self.mhsa_path_dropout = StochasticDepth(path_dropout * mix_block_ratio)\n",
        "        self.projection = PatchEmbed(self.mhca_out_channels, strides=1)\n",
        "        self.mhca = MHCA(self.mhca_out_channels, head_dim=head_dim)\n",
        "        self.mhca_path_dropout = StochasticDepth(\n",
        "            path_dropout * (1 - mix_block_ratio))\n",
        "        self.norm2 = layers.BatchNormalization(epsilon=EPSILON)\n",
        "        self.mlp = mlp(filters, mlp_ratio=mlp_ratio, drop=drop)\n",
        "        self.mlp_path_dropout = StochasticDepth(path_dropout)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "        B, C, H, W = x.shape\n",
        "        out = self.norm1(x)\n",
        "        out = rearrange(out, \"b h w c -> b (h w) c\")\n",
        "        out = self.mhsa_path_dropout(self.e_mhsa(out))\n",
        "        x = x + rearrange(out, \"b (h w) c -> b h w c\", h=H)\n",
        "        out = self.projection(x)\n",
        "        out = out + self.mhca_path_dropout(self.mhca(out))\n",
        "        x = tf.concat([x, out], axis=-1)\n",
        "        out = self.norm2(x)\n",
        "        x = x + self.mlp_path_dropout(self.mlp(out))\n",
        "        return x\n",
        "\n",
        "'''input = Input((256,256,24))\n",
        "test = NTB(128,\n",
        "           path_dropout=0.036363635,\n",
        "           strides=4,\n",
        "           sr_ratio=5,\n",
        "           head_dim=4,\n",
        "           mix_block_ratio=0.75,\n",
        "           attn_drop=0,\n",
        "           drop=0,\n",
        "           )\n",
        "x = test(input)\n",
        "a=1'''\n",
        "\n",
        "\n",
        "\n",
        "class GRID():\n",
        "        # 读图像文件\n",
        "        def read_img(self, filename):\n",
        "            dataset = gdal.Open(filename)\n",
        "            # 打开文件\n",
        "            im_width = dataset.RasterXSize  # 栅格矩阵的列数\n",
        "            im_height = dataset.RasterYSize  # 栅格矩阵的行数\n",
        "\n",
        "            im_geotrans = dataset.GetGeoTransform()  # 仿射矩阵\n",
        "            im_proj = dataset.GetProjection()  # 地图投影信息\n",
        "            im_data = dataset.ReadAsArray(0, 0, im_width, im_height)  # 将数据写成数组，对应栅格矩阵\n",
        "            im_data = np.array(im_data)\n",
        "            sp = im_data.shape\n",
        "            if im_data.ndim == 2:\n",
        "                im_data2 = im_data[:, :, np.newaxis]\n",
        "            else:\n",
        "                im_data2 = np.zeros((im_height, im_width, sp[0]))\n",
        "                for bands in range(0, sp[0]):\n",
        "                    im_data2[:, :, bands] = im_data[bands, :, :]\n",
        "\n",
        "            del dataset\n",
        "            return im_height, im_width, im_data2\n",
        "\n",
        "        def write_img(self, filename, im_proj, im_geotrans, im_data2):\n",
        "            # gdal数据类型包括\n",
        "            # gdal.GDT_Byte,\n",
        "            # gdal .GDT_UInt16, gdal.GDT_Int16, gdal.GDT_UInt32, gdal.GDT_Int32,\n",
        "            # gdal.GDT_Float32, gdal.GDT_Float64\n",
        "            sp = im_data2.shape\n",
        "            if len(sp) > 2:\n",
        "                im_data = np.zeros((sp[2], sp[0], sp[1]))\n",
        "                for bands in range(0, sp[2]):\n",
        "                    im_data[bands, :, :] = im_data2[:, :, bands]\n",
        "                print(im_data.shape)\n",
        "            else:\n",
        "                im_data = im_data2\n",
        "\n",
        "            # 判断栅格数据的数据类型\n",
        "            if 'int8' in im_data.dtype.name:\n",
        "                datatype = gdal.GDT_Byte\n",
        "            elif 'int16' in im_data.dtype.name:\n",
        "                datatype = gdal.GDT_UInt16\n",
        "            else:\n",
        "                datatype = gdal.GDT_Float32\n",
        "\n",
        "            # 判读数组维数\n",
        "            if len(im_data.shape) == 3:\n",
        "                im_bands, im_height, im_width = im_data.shape\n",
        "            else:\n",
        "                im_bands, (im_height, im_width) = 1, im_data.shape\n",
        "\n",
        "            # 创建文件\n",
        "            driver = gdal.GetDriverByName(\"ENVI\")  # 数据类型必须有，因为要计算需要多大内存空间\n",
        "            dataset = driver.Create(filename, im_width, im_height, im_bands, datatype)\n",
        "\n",
        "            #dataset.SetGeoTransform(im_geotrans)  # 写入仿射变换参数\n",
        "            #dataset.SetProjection(im_proj)  # 写入投影\n",
        "\n",
        "            if im_bands == 1:\n",
        "                dataset.GetRasterBand(1).WriteArray(im_data)  # 写入数组数据\n",
        "            else:\n",
        "                for i in range(im_bands):\n",
        "                    dataset.GetRasterBand(i + 1).WriteArray(im_data[i])\n",
        "\n",
        "            del dataset\n",
        "\n",
        "        def restore4d_over(self, data4d, patchsize, sp, jg):\n",
        "\n",
        "            spp = data4d.shape\n",
        "            sm = math.floor((sp[1] - 2 * jg) / (patchsize - 2 * jg))\n",
        "            rex = np.zeros((math.floor(spp[0] / sm) * (patchsize - 2 * jg), sm * (patchsize - 2 * jg), sp[2]))\n",
        "            for ii in range(0, spp[0]):\n",
        "                mm = math.floor(ii / sm)\n",
        "                nn = ii % sm\n",
        "                rex[mm * (patchsize - 2 * jg):(mm + 1) * (patchsize - 2 * jg),\n",
        "                nn * (patchsize - 2 * jg):(nn + 1) * (patchsize - 2 * jg), :] = data4d[ii, jg:patchsize - jg,\n",
        "                                                                                jg:patchsize - jg, :]\n",
        "            return rex\n",
        "\n",
        "        def prepare4d_over(self, img, patchsize, jg):\n",
        "            sp = img.shape\n",
        "            mnum = math.floor((sp[0] - 2 * jg) / (patchsize - 2 * jg))\n",
        "            nnum = math.floor((sp[1] - 2 * jg) / (patchsize - 2 * jg))\n",
        "            result = np.zeros((mnum * nnum, patchsize, patchsize, sp[2]))\n",
        "            count = -1\n",
        "            for i in range(0, mnum):\n",
        "                for j in range(0, nnum):\n",
        "                    count += 1\n",
        "                    result[count, :, :, :] = img[(patchsize - 2 * jg) * i:(patchsize - 2 * jg) * i + patchsize,(patchsize - 2 * jg) * j: (patchsize - 2 * jg) * j + patchsize, :]\n",
        "            return result, sp\n",
        "\n",
        "class Scaler(layers.Layer):\n",
        "    \"\"\"特殊的scale层\n",
        "    \"\"\"\n",
        "    def __init__(self, tau=0.5, mode='positive', **kwargs):\n",
        "        super(Scaler, self).__init__(**kwargs)\n",
        "        self.tau = tau\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(Scaler, self).build(input_shape)\n",
        "        self.scale = self.add_weight(\n",
        "            name='scale', shape=(input_shape[-1],), initializer='zeros'\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, mode='positive'):\n",
        "        if mode == 'positive':\n",
        "            scale = self.tau + (1 - self.tau) * K.sigmoid(self.scale)\n",
        "        else:\n",
        "            scale = (1 - self.tau) * K.sigmoid(-self.scale)\n",
        "        return inputs * K.sqrt(scale)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'tau': self.tau}\n",
        "        base_config = super(Scaler, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class ETmodel:\n",
        "    def __init__(self,dirr,patchsize,jg,epochs,resname):\n",
        "        self.patchsize = patchsize\n",
        "        self.jg = jg\n",
        "        self.grid = GRID()\n",
        "        lr_train, vs_train = self.read_data(dirr,patchsize,jg)\n",
        "        print('data read!')\n",
        "        model = self.buildmodel(input_shape1=(lr_train.shape[1], lr_train.shape[2], lr_train.shape[3]),input_shape2=(vs_train.shape[1], vs_train.shape[2],vs_train.shape[3]),out_chans=vs_train.shape[-1],patchsize=64)\n",
        "        print('model built!')\n",
        "        self.train_model(model, lr_train, vs_train, epochs,'vs_model')\n",
        "        nmodel = keras.Model(model.input,model.get_layer(name='output_layer').output)\n",
        "        #plot_model(model, to_file='modell.png',show_shapes=True)\n",
        "        self.pred_model(nmodel,dirr,patchsize,jg)\n",
        "\n",
        "    def buildmodel(self,input_shape1=(None,None,1),input_shape2=(None,None,3),out_chans=1,patchsize=64):\n",
        "        #vau_e, vau_d = self.autoencoder(input_shape1=input_shape1,latent_dim=1024,out_chans=1,patchsize=64)\n",
        "        #iau_e, iau_d = self.autoencoder(input_shape1=input_shape2,latent_dim=1024,out_chans=1,patchsize=64)\n",
        "        #return iau_e, iau_d, vau_e, vau_d\n",
        "        input1 = layers.Input(shape=input_shape1,name='i_input')\n",
        "        input2 = layers.Input(shape=input_shape2,name='v_input')\n",
        "        x = layers.Conv2D(filters=64, kernel_size=1, data_format='channels_last', padding='same')(input1)\n",
        "        x = layers.BatchNormalization(axis=1)(x)\n",
        "        x = layers.LeakyReLU(alpha=0.3)(x)\n",
        "\n",
        "        for i in range(0, 3):\n",
        "            x = self._convolutional_block(x, [64, 32, 16], 'p', str(i))\n",
        "\n",
        "        x = layers.Conv2D(filters=16, kernel_size=1, data_format='channels_last', padding='same')(x)\n",
        "        x = layers.BatchNormalization(axis=-1)(x)\n",
        "        x = layers.LeakyReLU(alpha=0.3)(x)\n",
        "\n",
        "        y = layers.Conv2D(filters=64, kernel_size=1, data_format='channels_last', padding='same')(input2)\n",
        "        y = layers.BatchNormalization(axis=1)(y)\n",
        "        y = layers.LeakyReLU(alpha=0.3)(y)\n",
        "\n",
        "        for i in range(0, 3):\n",
        "            y = self._convolutional_block(y, [64, 32, 16], 'p', str(i))\n",
        "\n",
        "        y = layers.Conv2D(filters=16, kernel_size=1, data_format='channels_last', padding='same')(y)\n",
        "        y = layers.BatchNormalization(axis=-1)(y)\n",
        "        y = layers.LeakyReLU(alpha=0.3)(y)\n",
        "\n",
        "        z = layers.Concatenate(axis=-1)([x,y])\n",
        "        z = layers.Conv2D(filters=64, kernel_size=1, data_format='channels_last', padding='same')(z)\n",
        "        z = layers.BatchNormalization(axis=1)(z)\n",
        "        z = layers.LeakyReLU(alpha=0.3)(z)\n",
        "\n",
        "        for i in range(0, 3):\n",
        "            z = self._convolutional_block(z, [64, 32, 16], 'p', str(i))\n",
        "\n",
        "        z = layers.Conv2D(filters=out_chans, kernel_size=1, data_format='channels_last', padding='same')(z)\n",
        "        z = layers.BatchNormalization(axis=-1)(z)\n",
        "        z = layers.LeakyReLU(alpha=0.3, name='output_layer')(z)\n",
        "\n",
        "        res1 = Lossi()([input1,z])\n",
        "        res2 = Losst()([input2,z])\n",
        "        res = res1 + res2\n",
        "\n",
        "        return keras.Model([input1,input2],res)\n",
        "\n",
        "\n",
        "    def _convolutional_block(self, X, filters, stage, block):\n",
        "        conv_name_base = 'res' + stage + block + '_branch'\n",
        "        bn_name_base = 'bn' + stage + block + '_branch'\n",
        "        lrelu_name_base = 'lrelu' + stage + block + '_branch'\n",
        "        # Retrieve Filters\n",
        "        F1, F2, F3 = filters\n",
        "        # Save the input value\n",
        "        X_shortcut = X\n",
        "        # ##### MAIN PATH #####\n",
        "        # First component of main path\n",
        "        X = layers.Conv2D(filters=F1, kernel_size=3, strides=1, padding='same',\n",
        "                   data_format='channels_last',\n",
        "                   kernel_initializer='glorot_uniform')(X)\n",
        "        X = layers.BatchNormalization(axis=-1)(X)\n",
        "        X = layers.LeakyReLU(alpha=0.3)(X)\n",
        "        ### START CODE HERE ##\n",
        "        # Second component of main path (≈3 lines)\n",
        "        X = layers.Conv2D(F2, 3, strides=1, padding='same', data_format='channels_last',\n",
        "                   kernel_initializer='glorot_uniform')(X)\n",
        "        X = layers.BatchNormalization(axis=-1, )(X)\n",
        "        X = layers.LeakyReLU(alpha=0.3)(X)\n",
        "        # Third component of main path (≈2 lines)\n",
        "        X = layers.Conv2D(F1, 3, strides=1, padding='same', data_format='channels_last',\n",
        "                   kernel_initializer='glorot_uniform')(X)\n",
        "        X = layers.BatchNormalization(axis=-1)(X)\n",
        "        X = layers.LeakyReLU(alpha=0.3)(X)\n",
        "        # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "        X = layers.Add()([X, X_shortcut])\n",
        "        X = layers.Activation('relu')(X)\n",
        "        return X\n",
        "\n",
        "    def _convolutional_block_reverse(self, X, filters, stage, block):\n",
        "        conv_name_base = 'res' + stage + block + '_branch'\n",
        "        bn_name_base = 'bn' + stage + block + '_branch'\n",
        "        lrelu_name_base = 'lrelu' + stage + block + '_branch'\n",
        "        # Retrieve Filters\n",
        "        F1, F2, F3 = filters\n",
        "        # Save the input value\n",
        "        X_shortcut = X\n",
        "        # ##### MAIN PATH #####\n",
        "        # First component of main path\n",
        "        X = layers.Conv2DTranspose(filters=F1, kernel_size=3, strides=1, padding='same',\n",
        "                   data_format='channels_last',\n",
        "                   kernel_initializer='glorot_uniform')(X)\n",
        "        X = layers.BatchNormalization(axis=-1)(X)\n",
        "        X = layers.LeakyReLU(alpha=0.3)(X)\n",
        "        ### START CODE HERE ##\n",
        "        # Second component of main path (≈3 lines)\n",
        "        X = layers.Conv2DTranspose(F2, 3, strides=1,padding='same', data_format='channels_last',\n",
        "                   kernel_initializer='glorot_uniform')(X)\n",
        "        X = layers.BatchNormalization(axis=-1)(X)\n",
        "        X = layers.LeakyReLU(alpha=0.3)(X)\n",
        "        # Third component of main path (≈2 lines)\n",
        "        X = layers.Conv2DTranspose(F1, 3, strides=1, padding='same', data_format='channels_last',\n",
        "                   kernel_initializer='glorot_uniform')(X)\n",
        "        X = layers.BatchNormalization(axis=-1)(X)\n",
        "        X = layers.LeakyReLU(alpha=0.3)(X)\n",
        "        # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "        X = layers.Add()([X, X_shortcut])\n",
        "        X = layers.Activation('relu')(X)\n",
        "        return X\n",
        "\n",
        "\n",
        "    def gaussian_down_sample(self,data,w,mask=0):\n",
        "      # masking mode\n",
        "      if np.isscalar(mask):\n",
        "        masking = 0\n",
        "      else:\n",
        "        masking = 1\n",
        "\n",
        "      xdata = data.shape[0]\n",
        "      ydata = data.shape[1]\n",
        "      band = data.shape[2]\n",
        "      hx = int(np.floor(xdata/w))\n",
        "      hy = int(np.floor(ydata/w))\n",
        "      HSI = np.zeros((hx, hy, band))\n",
        "      sig = w/2.35482\n",
        "\n",
        "      if masking == 0: # without mask\n",
        "        if np.mod(w,2)==0:\n",
        "            H1 = self.gaussian_filter2d((w,w),sig).reshape(w,w,1)\n",
        "            H2 = self.gaussian_filter2d((w*2,w*2),sig).reshape(w*2,w*2,1)\n",
        "            for x in range(hx):\n",
        "                for y in range(hy):\n",
        "                    if x==0 or x==hx-1 or y==0 or y==hy-1:\n",
        "                        HSI[x,y,:] = (np.double( data[x*w:(x+1)*w,y*w:(y+1)*w,:] ) * np.tile(H1,(1,1,band))).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "                    else:\n",
        "                        HSI[x,y,:] = (np.double( data[x*w-int(w/2):(x+1)*w+int(w/2),y*w-int(w/2):(y+1)*w+int(w/2),:] ) * np.tile(H2,(1,1,band))).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "        else:\n",
        "            H1 = self.gaussian_filter2d((w,w),sig).reshape(w,w,1)\n",
        "            H2 = self.gaussian_filter2d((w*2-1,w*2-1),sig).reshape(w*2-1,w*2-1,1)\n",
        "            for x in range(hx):\n",
        "                for y in range(hy):\n",
        "                    if x==0 or x==hx-1 or y==0 or y==hy-1:\n",
        "                        HSI[x,y,:] = (np.double( data[x*w:(x+1)*w,y*w:(y+1)*w,:] ) * np.tile(H1,(1,1,band)) ).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "                    else:\n",
        "                        HSI[x,y,:] = (np.double( data[x*w-int((w-1)/2):(x+1)*w+int((w-1)/2),y*w-int((w-1)/2):(y+1)*w+int((w-1)/2),:] ) * np.tile(H2,(1,1,band))).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "      else: # with mask\n",
        "        if np.mod(w,2)==0:\n",
        "            H1 = self.gaussian_filter2d((w,w),sig).reshape(w,w,1)\n",
        "            H2 = self.gaussian_filter2d((w*2,w*2),sig).reshape(w*2,w*2,1)\n",
        "            for x in range(hx):\n",
        "                for y in range(hy):\n",
        "                    mask_tmp = mask[x*w:(x+1)*w,y*w:(y+1)*w]\n",
        "                    if mask_tmp.sum() == w**2:\n",
        "                        if x==0 or x==hx-1 or y==0 or y==hy-1:\n",
        "                            HSI[x,y,:] = (np.double( data[x*w:(x+1)*w,y*w:(y+1)*w,:] ) * np.tile(H1,(1,1,band))).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "                        else:\n",
        "                            HSI[x,y,:] = (np.double( data[x*w-int(w/2):(x+1)*w+int(w/2),y*w-int(w/2):(y+1)*w+int(w/2),:] ) * np.tile(H2,(1,1,band))).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "        else:\n",
        "            H1 = self.gaussian_filter2d((w,w),sig).reshape(w,w,1)\n",
        "            H2 = self.gaussian_filter2d((w*2-1,w*2-1),sig).reshape(w*2-1,w*2-1,1)\n",
        "            for x in range(hx):\n",
        "                for y in range(hy):\n",
        "                    mask_tmp = mask[x*w:(x+1)*w,y*w:(y+1)*w]\n",
        "                    if mask_tmp.sum() == w**2:\n",
        "                        if x==0 or x==hx-1 or y==0 or y==hy-1:\n",
        "                            HSI[x,y,:] = (np.double( data[x*w:(x+1)*w,y*w:(y+1)*w,:] ) * np.tile(H1,(1,1,band)) ).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "                        else:\n",
        "                            HSI[x,y,:] = (np.double( data[x*w-int((w-1)/2):(x+1)*w+int((w-1)/2),y*w-int((w-1)/2):(y+1)*w+int((w-1)/2),:] ) * np.tile(H2,(1,1,band))).sum(axis=0).sum(axis=0).reshape(1,1,band)\n",
        "\n",
        "      return HSI\n",
        "\n",
        "    def gaussian_filter2d(self,shape=(3,3),sigma=1):\n",
        "      m,n = [(ss-1.)/2. for ss in shape]\n",
        "      y,x = np.ogrid[-m:m+1,-n:n+1]\n",
        "      h = np.exp( -(x**2 + y**2) / (2.*sigma**2) )\n",
        "      h[ h < np.finfo(h.dtype).eps*h.max() ] = 0\n",
        "      sumh = h.sum()\n",
        "      if sumh != 0:\n",
        "        h /= sumh\n",
        "      return h\n",
        "\n",
        "    def read_data(self,dirr,patchsize,jg):\n",
        "        lrdata = []\n",
        "        vsdata = []\n",
        "        zdlr = {}\n",
        "        zdvs = {}\n",
        "        lr_train = []\n",
        "        vs_train = []\n",
        "        lr_pred = []\n",
        "        lr_tar = []\n",
        "        dirl = dirr + r'/lr'\n",
        "        dirv = dirr + r'/vis'\n",
        "        listl = os.listdir(dirl)\n",
        "        listv = os.listdir(dirv)\n",
        "        nums = len(dirl)\n",
        "        indd = np.arange(nums)[0:60]\n",
        "        random.shuffle(indd)\n",
        "        listl = [listl[i] for i in indd]\n",
        "        listv = [listv[i] for i in indd]\n",
        "\n",
        "        for ii in range(0,len(listl)):\n",
        "          lfile = listl[ii]\n",
        "          lfile = dirl + r'/' + lfile\n",
        "          imgr = cv2.imread(lfile,0)\n",
        "          #gauss = np.random.normal(0,25,(imgr.shape[0],imgr.shape[1]))\n",
        "          #imgr = imgr + gauss\n",
        "\n",
        "          vfile = listv[ii]\n",
        "          vfile = dirv + r'/' + listl[ii]\n",
        "          imgv = cv2.imread(vfile,cv2.IMREAD_COLOR)\n",
        "\n",
        "          #vs_train\n",
        "          imgv1 = cv2.resize(imgv,(int(imgv.shape[0]/3*2),int(imgv.shape[1]/3*2)))\n",
        "\n",
        "          if imgr.shape != imgv1.shape:\n",
        "            sp = [min(imgr.shape[0],imgv1.shape[0]),min(imgr.shape[1],imgv1.shape[1])]\n",
        "            imgr = imgr[:sp[0],:sp[1]]\n",
        "            imgv1 = imgv1[:sp[0],:sp[1],:]\n",
        "\n",
        "          imgr = imgr[:,:,np.newaxis]\n",
        "\n",
        "          if lr_train == []:\n",
        "            lr_train,sp = self.grid.prepare4d_over(imgr,patchsize,jg)\n",
        "          else:\n",
        "            temp,sp = self.grid.prepare4d_over(imgr,patchsize,jg)\n",
        "            lr_train = np.concatenate((lr_train,temp),axis=0)\n",
        "\n",
        "          if vs_train == []:\n",
        "            vs_train,sp = self.grid.prepare4d_over(imgv1,patchsize,jg)\n",
        "          else:\n",
        "            temp,sp = self.grid.prepare4d_over(imgv1,patchsize,jg)\n",
        "            vs_train = np.concatenate((vs_train,temp),axis=0)\n",
        "\n",
        "        print(lr_train.shape)\n",
        "        print(vs_train.shape)\n",
        "\n",
        "        indd = np.arange(0,lr_train.shape[0])\n",
        "        np.random.shuffle(indd)\n",
        "        lr_train = lr_train[indd,:,:,:]\n",
        "        vs_train = vs_train[indd,:,:,:]\n",
        "        return lr_train, vs_train\n",
        "\n",
        "    def compute_loss(self, model1, model2, x, epoch):\n",
        "      x = tf.cast(x,dtype=tf.float32)\n",
        "      mean, logvar = model1(x)\n",
        "      z = self.sampling(mean, logvar)\n",
        "      x_logit = model2(z)\n",
        "\n",
        "      #(1-1/epoch)*\n",
        "      cross_ent = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x), axis=[1, 2, 3])\n",
        "      KLD = -0.5 * tf.reduce_sum(1 + logvar- tf.pow(mean, 2) - tf.exp(logvar), axis=-1)\n",
        "      return tf.reduce_mean(cross_ent + KLD)\n",
        "\n",
        "    def compute_apply_gradients(self, model1, model2, model, x, optimizer):\n",
        "      with tf.GradientTape() as tape:\n",
        "        loss = self.compute_loss(model1, model2, x)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    def sampling(self, z_mean, z_log_var):\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.random.normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    def train_model(self,model,x1,x2,epochs,modelname):\n",
        "        print(x1.shape)\n",
        "        print(x2.shape)\n",
        "        minn = min(x1.shape[0],x2.shape[0])\n",
        "        optim = tf.keras.optimizers.Adam(lr=0.001)\n",
        "        model.compile(loss='mse', optimizer=optim, metrics=['accuracy'])\n",
        "        if os.path.isfile('pres_model.h5'):\n",
        "            model.load_weights('pres_model.h5')\n",
        "            self.status = 1\n",
        "            # return\n",
        "        else:\n",
        "            callbacks1 = EarlyStopping(monitor='loss', min_delta=0, patience=15, verbose=0, mode='auto',\n",
        "                                       baseline=None, restore_best_weights=True)\n",
        "            reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                                          patience=7, min_lr=0.00001)\n",
        "            # history = self.p_model.fit(x=self.hd5mu[:,np.linspace(0,8,5,dtype='int8'),:,:,:], y=self.hd5l, batch_size=32, callbacks = [callbacks1,reduce_lr],epochs=self.epochs, validation_split=0.1)\n",
        "            history = model.fit(x=[x1[:minn,:,:,:]/100,x2[:minn,:,:,:]/100], y=np.zeros((minn,x2.shape[1],x2.shape[2],x2.shape[3])),\n",
        "                                batch_size=8,\n",
        "                                       callbacks=[callbacks1, reduce_lr],\n",
        "                                       epochs=epochs, validation_split=0.1)\n",
        "            #history = self.model.fit_generator(self.datagen.flow([x1[:minn,:,:,:]/1000,x2[:minn,:,:,:]/1000],\n",
        "            #                                           y=y[:minn,:,:,:]/1000),\n",
        "            #                                           epochs=epochs,\n",
        "            #                                           steps_per_epoch=minn/4)\n",
        "            model.save_weights('pres_model.h5')\n",
        "            loss_history = history.history[\"loss\"]\n",
        "            val_loss_history = history.history['val_loss']\n",
        "            numpy_loss_history = np.array(loss_history)\n",
        "            numpy_val_loss = np.array(val_loss_history)\n",
        "            np.savetxt('pres_loss.txt', numpy_loss_history,delimiter=\",\")\n",
        "            np.savetxt('pres_val_loss.txt', numpy_val_loss,delimiter=\",\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def pred_model(self,model,dirr,patchsize,jg):\n",
        "        dirl = dirr + r'/lr'\n",
        "        dirv = dirr + r'/vis'\n",
        "        dirres = dirr + r'/res/'\n",
        "        listl = os.listdir(dirl)\n",
        "        listv = os.listdir(dirv)\n",
        "        for ii in range(0,len(listl)):\n",
        "          lfile = listl[ii]\n",
        "          lfile = dirl + r'/' + lfile\n",
        "          imgr = cv2.imread(lfile,0)\n",
        "\n",
        "          vfile = listv[ii]\n",
        "          vfile = dirv + r'/' + listl[ii]\n",
        "          imgv = cv2.imread(vfile,cv2.IMREAD_COLOR)\n",
        "\n",
        "          imgr1 = cv2.resize(imgr,(int(imgr.shape[0]/2*3),int(imgr.shape[1]/2*3)))\n",
        "          imgr1 = imgr1[:,:,np.newaxis]\n",
        "\n",
        "          if imgr1.shape != imgv.shape:\n",
        "            sp = [min(imgr1.shape[0],imgv.shape[0]),min(imgr1.shape[1],imgv.shape[1])]\n",
        "            imgr1 = imgr1[:sp[0],:sp[1],:]\n",
        "            imgv = imgv[:sp[0],:sp[1],:]\n",
        "\n",
        "          lr_tar,sp = self.grid.prepare4d_over(imgr1,patchsize,7)\n",
        "          vsdata,sp = self.grid.prepare4d_over(imgv,patchsize,7)\n",
        "\n",
        "          res4d = model.predict([lr_tar/100,vsdata/100], batch_size=8)*100\n",
        "          res = self.grid.restore4d_over(res4d,patchsize,sp,7)\n",
        "          cv2.imwrite(dirres + listl[ii][:-4]+'_fus.png', np.array(np.squeeze(res),dtype=int))\n",
        "\n",
        "\n",
        "class Lossi(layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(Lossi, self).__init__()\n",
        "\n",
        "    # 通过回调函数计算\n",
        "    def call(self, inputs):\n",
        "        ii, f = inputs\n",
        "        fi = tf.reduce_mean(f,axis=-1,keepdims=True)\n",
        "        return tf.abs(ii - fi)/ii.shape[1]/ii.shape[2]\n",
        "\n",
        "class Losst(layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(Losst, self).__init__()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        v, f = inputs\n",
        "        dxf, dyf = tf.image.image_gradients(f)\n",
        "        dxv, dyv = tf.image.image_gradients(tf.reduce_mean(v,axis=-1)[...,tf.newaxis])\n",
        "        dxx = tf.abs(dxv-tf.abs(dxf))\n",
        "        dyy = tf.abs(dyv-tf.abs(dyf))\n",
        "        return dxx/dxx.shape[1]/dxx.shape[2]+dyy/dyy.shape[1]/dyy.shape[2]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    dirr = r'/content/drive/MyDrive/new'\n",
        "    os.chdir(dirr)\n",
        "    print(os.getcwd())\n",
        "    print(os.listdir())\n",
        "    patchsize = 64\n",
        "    jg = 0\n",
        "    epochs = 1000\n",
        "\n",
        "    starttime = datetime.datetime.now()\n",
        "    ET = ETmodel(dirr,patchsize,jg,epochs,'')\n",
        "    endtime = datetime.datetime.now()\n",
        "    print('total time is ' + str(endtime - starttime) + 's')\n",
        "    np.savetxt('time_cst.txt', np.array([(endtime - starttime).seconds]), delimiter=\",\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zePsEOqyT_Ax",
        "outputId": "21fd9a4c-1724-45a0-e2c2-17db3252ca24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1NGc_AhpYbtXwsERLnGHUwsUHrAPuyqR5/new\n",
            "['vis2pan', 'lr', 'vis', 'res']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-5b76953115ae>:904: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if lr_train == []:\n",
            "<ipython-input-6-5b76953115ae>:910: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  if vs_train == []:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2320, 64, 64, 1)\n",
            "(2320, 64, 64, 3)\n",
            "data read!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model built!\n",
            "(2320, 64, 64, 1)\n",
            "(2320, 64, 64, 3)\n",
            "Epoch 1/1000\n",
            "261/261 [==============================] - 47s 78ms/step - loss: 8.8199e-08 - accuracy: 0.2402 - val_loss: 4.5435e-08 - val_accuracy: 0.1646 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 3.7821e-08 - accuracy: 0.2599 - val_loss: 3.3956e-08 - val_accuracy: 0.2428 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "261/261 [==============================] - 18s 67ms/step - loss: 2.9584e-08 - accuracy: 0.2874 - val_loss: 2.4493e-08 - val_accuracy: 0.2791 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 2.5386e-08 - accuracy: 0.2997 - val_loss: 2.1271e-08 - val_accuracy: 0.2914 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 2.2401e-08 - accuracy: 0.3098 - val_loss: 1.8988e-08 - val_accuracy: 0.2949 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "261/261 [==============================] - 19s 71ms/step - loss: 2.0275e-08 - accuracy: 0.3142 - val_loss: 1.6675e-08 - val_accuracy: 0.3052 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.8495e-08 - accuracy: 0.3147 - val_loss: 1.5234e-08 - val_accuracy: 0.3051 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "261/261 [==============================] - 17s 66ms/step - loss: 1.6784e-08 - accuracy: 0.3183 - val_loss: 1.3301e-08 - val_accuracy: 0.3088 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.6091e-08 - accuracy: 0.3206 - val_loss: 1.2447e-08 - val_accuracy: 0.3079 - lr: 2.0000e-04\n",
            "Epoch 10/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.5758e-08 - accuracy: 0.3198 - val_loss: 1.2929e-08 - val_accuracy: 0.3063 - lr: 2.0000e-04\n",
            "Epoch 11/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.5664e-08 - accuracy: 0.3191 - val_loss: 1.2275e-08 - val_accuracy: 0.3084 - lr: 2.0000e-04\n",
            "Epoch 12/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.5777e-08 - accuracy: 0.3197 - val_loss: 1.2582e-08 - val_accuracy: 0.3081 - lr: 2.0000e-04\n",
            "Epoch 13/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.5324e-08 - accuracy: 0.3248 - val_loss: 1.2073e-08 - val_accuracy: 0.3095 - lr: 2.0000e-04\n",
            "Epoch 14/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4859e-08 - accuracy: 0.3199 - val_loss: 1.1699e-08 - val_accuracy: 0.3075 - lr: 2.0000e-04\n",
            "Epoch 15/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4623e-08 - accuracy: 0.3209 - val_loss: 1.1464e-08 - val_accuracy: 0.3068 - lr: 2.0000e-04\n",
            "Epoch 16/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4390e-08 - accuracy: 0.3199 - val_loss: 1.1488e-08 - val_accuracy: 0.3080 - lr: 4.0000e-05\n",
            "Epoch 17/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4394e-08 - accuracy: 0.3228 - val_loss: 1.1574e-08 - val_accuracy: 0.3095 - lr: 4.0000e-05\n",
            "Epoch 18/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4290e-08 - accuracy: 0.3189 - val_loss: 1.1434e-08 - val_accuracy: 0.3087 - lr: 4.0000e-05\n",
            "Epoch 19/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4332e-08 - accuracy: 0.3242 - val_loss: 1.1721e-08 - val_accuracy: 0.3081 - lr: 4.0000e-05\n",
            "Epoch 20/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.4292e-08 - accuracy: 0.3226 - val_loss: 1.1332e-08 - val_accuracy: 0.3092 - lr: 4.0000e-05\n",
            "Epoch 21/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4201e-08 - accuracy: 0.3196 - val_loss: 1.1654e-08 - val_accuracy: 0.3062 - lr: 4.0000e-05\n",
            "Epoch 22/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.4219e-08 - accuracy: 0.3210 - val_loss: 1.1029e-08 - val_accuracy: 0.3102 - lr: 4.0000e-05\n",
            "Epoch 23/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4277e-08 - accuracy: 0.3259 - val_loss: 1.1225e-08 - val_accuracy: 0.3097 - lr: 1.0000e-05\n",
            "Epoch 24/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4218e-08 - accuracy: 0.3212 - val_loss: 1.1512e-08 - val_accuracy: 0.3062 - lr: 1.0000e-05\n",
            "Epoch 25/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.4200e-08 - accuracy: 0.3216 - val_loss: 1.1257e-08 - val_accuracy: 0.3075 - lr: 1.0000e-05\n",
            "Epoch 26/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.4285e-08 - accuracy: 0.3204 - val_loss: 1.0923e-08 - val_accuracy: 0.3095 - lr: 1.0000e-05\n",
            "Epoch 27/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.4267e-08 - accuracy: 0.3201 - val_loss: 1.1234e-08 - val_accuracy: 0.3068 - lr: 1.0000e-05\n",
            "Epoch 28/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4075e-08 - accuracy: 0.3245 - val_loss: 1.1128e-08 - val_accuracy: 0.3113 - lr: 1.0000e-05\n",
            "Epoch 29/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4234e-08 - accuracy: 0.3224 - val_loss: 1.0939e-08 - val_accuracy: 0.3093 - lr: 1.0000e-05\n",
            "Epoch 30/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.4217e-08 - accuracy: 0.3217 - val_loss: 1.0903e-08 - val_accuracy: 0.3089 - lr: 1.0000e-05\n",
            "Epoch 31/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4256e-08 - accuracy: 0.3198 - val_loss: 1.0963e-08 - val_accuracy: 0.3100 - lr: 1.0000e-05\n",
            "Epoch 32/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4145e-08 - accuracy: 0.3239 - val_loss: 1.0651e-08 - val_accuracy: 0.3107 - lr: 1.0000e-05\n",
            "Epoch 33/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4289e-08 - accuracy: 0.3210 - val_loss: 1.1248e-08 - val_accuracy: 0.3070 - lr: 1.0000e-05\n",
            "Epoch 34/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.4101e-08 - accuracy: 0.3235 - val_loss: 1.1393e-08 - val_accuracy: 0.3066 - lr: 1.0000e-05\n",
            "Epoch 35/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.4251e-08 - accuracy: 0.3221 - val_loss: 1.0959e-08 - val_accuracy: 0.3068 - lr: 1.0000e-05\n",
            "Epoch 36/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4180e-08 - accuracy: 0.3217 - val_loss: 1.0891e-08 - val_accuracy: 0.3103 - lr: 1.0000e-05\n",
            "Epoch 37/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.4095e-08 - accuracy: 0.3225 - val_loss: 1.1413e-08 - val_accuracy: 0.3078 - lr: 1.0000e-05\n",
            "Epoch 38/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.4057e-08 - accuracy: 0.3216 - val_loss: 1.1725e-08 - val_accuracy: 0.3046 - lr: 1.0000e-05\n",
            "Epoch 39/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4026e-08 - accuracy: 0.3203 - val_loss: 1.1227e-08 - val_accuracy: 0.3089 - lr: 1.0000e-05\n",
            "Epoch 40/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4207e-08 - accuracy: 0.3234 - val_loss: 1.0849e-08 - val_accuracy: 0.3092 - lr: 1.0000e-05\n",
            "Epoch 41/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4230e-08 - accuracy: 0.3228 - val_loss: 1.0700e-08 - val_accuracy: 0.3082 - lr: 1.0000e-05\n",
            "Epoch 42/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3950e-08 - accuracy: 0.3181 - val_loss: 1.1384e-08 - val_accuracy: 0.3057 - lr: 1.0000e-05\n",
            "Epoch 43/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4154e-08 - accuracy: 0.3231 - val_loss: 1.1472e-08 - val_accuracy: 0.3066 - lr: 1.0000e-05\n",
            "Epoch 44/1000\n",
            "261/261 [==============================] - 17s 66ms/step - loss: 1.4077e-08 - accuracy: 0.3200 - val_loss: 1.0897e-08 - val_accuracy: 0.3068 - lr: 1.0000e-05\n",
            "Epoch 45/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4079e-08 - accuracy: 0.3257 - val_loss: 1.1411e-08 - val_accuracy: 0.3072 - lr: 1.0000e-05\n",
            "Epoch 46/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4235e-08 - accuracy: 0.3225 - val_loss: 1.0993e-08 - val_accuracy: 0.3067 - lr: 1.0000e-05\n",
            "Epoch 47/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4032e-08 - accuracy: 0.3225 - val_loss: 1.1124e-08 - val_accuracy: 0.3085 - lr: 1.0000e-05\n",
            "Epoch 48/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4114e-08 - accuracy: 0.3228 - val_loss: 1.0998e-08 - val_accuracy: 0.3050 - lr: 1.0000e-05\n",
            "Epoch 49/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4109e-08 - accuracy: 0.3212 - val_loss: 1.0718e-08 - val_accuracy: 0.3087 - lr: 1.0000e-05\n",
            "Epoch 50/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4297e-08 - accuracy: 0.3220 - val_loss: 1.1030e-08 - val_accuracy: 0.3065 - lr: 1.0000e-05\n",
            "Epoch 51/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4218e-08 - accuracy: 0.3208 - val_loss: 1.0819e-08 - val_accuracy: 0.3080 - lr: 1.0000e-05\n",
            "Epoch 52/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.3851e-08 - accuracy: 0.3188 - val_loss: 1.0955e-08 - val_accuracy: 0.3068 - lr: 1.0000e-05\n",
            "Epoch 53/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3970e-08 - accuracy: 0.3222 - val_loss: 1.1111e-08 - val_accuracy: 0.3071 - lr: 1.0000e-05\n",
            "Epoch 54/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.3873e-08 - accuracy: 0.3221 - val_loss: 1.0675e-08 - val_accuracy: 0.3087 - lr: 1.0000e-05\n",
            "Epoch 55/1000\n",
            "261/261 [==============================] - 17s 66ms/step - loss: 1.3831e-08 - accuracy: 0.3200 - val_loss: 1.0974e-08 - val_accuracy: 0.3067 - lr: 1.0000e-05\n",
            "Epoch 56/1000\n",
            "261/261 [==============================] - 17s 66ms/step - loss: 1.4097e-08 - accuracy: 0.3223 - val_loss: 1.0943e-08 - val_accuracy: 0.3066 - lr: 1.0000e-05\n",
            "Epoch 57/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3868e-08 - accuracy: 0.3227 - val_loss: 1.0866e-08 - val_accuracy: 0.3100 - lr: 1.0000e-05\n",
            "Epoch 58/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3721e-08 - accuracy: 0.3194 - val_loss: 1.1026e-08 - val_accuracy: 0.3074 - lr: 1.0000e-05\n",
            "Epoch 59/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3861e-08 - accuracy: 0.3248 - val_loss: 1.0705e-08 - val_accuracy: 0.3081 - lr: 1.0000e-05\n",
            "Epoch 60/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3898e-08 - accuracy: 0.3185 - val_loss: 1.0962e-08 - val_accuracy: 0.3064 - lr: 1.0000e-05\n",
            "Epoch 61/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3990e-08 - accuracy: 0.3199 - val_loss: 1.0811e-08 - val_accuracy: 0.3088 - lr: 1.0000e-05\n",
            "Epoch 62/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4106e-08 - accuracy: 0.3242 - val_loss: 1.0770e-08 - val_accuracy: 0.3093 - lr: 1.0000e-05\n",
            "Epoch 63/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4200e-08 - accuracy: 0.3234 - val_loss: 1.0997e-08 - val_accuracy: 0.3108 - lr: 1.0000e-05\n",
            "Epoch 64/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3731e-08 - accuracy: 0.3249 - val_loss: 1.0638e-08 - val_accuracy: 0.3115 - lr: 1.0000e-05\n",
            "Epoch 65/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3854e-08 - accuracy: 0.3211 - val_loss: 1.0788e-08 - val_accuracy: 0.3078 - lr: 1.0000e-05\n",
            "Epoch 66/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3937e-08 - accuracy: 0.3226 - val_loss: 1.0744e-08 - val_accuracy: 0.3089 - lr: 1.0000e-05\n",
            "Epoch 67/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3767e-08 - accuracy: 0.3215 - val_loss: 1.1008e-08 - val_accuracy: 0.3088 - lr: 1.0000e-05\n",
            "Epoch 68/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3517e-08 - accuracy: 0.3203 - val_loss: 1.0650e-08 - val_accuracy: 0.3071 - lr: 1.0000e-05\n",
            "Epoch 69/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.3818e-08 - accuracy: 0.3230 - val_loss: 1.0843e-08 - val_accuracy: 0.3081 - lr: 1.0000e-05\n",
            "Epoch 70/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3596e-08 - accuracy: 0.3231 - val_loss: 1.0868e-08 - val_accuracy: 0.3091 - lr: 1.0000e-05\n",
            "Epoch 71/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3639e-08 - accuracy: 0.3203 - val_loss: 1.0380e-08 - val_accuracy: 0.3089 - lr: 1.0000e-05\n",
            "Epoch 72/1000\n",
            "261/261 [==============================] - 17s 66ms/step - loss: 1.3500e-08 - accuracy: 0.3199 - val_loss: 1.0842e-08 - val_accuracy: 0.3086 - lr: 1.0000e-05\n",
            "Epoch 73/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.4022e-08 - accuracy: 0.3218 - val_loss: 1.0871e-08 - val_accuracy: 0.3057 - lr: 1.0000e-05\n",
            "Epoch 74/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.4023e-08 - accuracy: 0.3243 - val_loss: 1.0872e-08 - val_accuracy: 0.3089 - lr: 1.0000e-05\n",
            "Epoch 75/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3658e-08 - accuracy: 0.3230 - val_loss: 1.0802e-08 - val_accuracy: 0.3096 - lr: 1.0000e-05\n",
            "Epoch 76/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3666e-08 - accuracy: 0.3210 - val_loss: 1.0848e-08 - val_accuracy: 0.3065 - lr: 1.0000e-05\n",
            "Epoch 77/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.3860e-08 - accuracy: 0.3221 - val_loss: 1.0484e-08 - val_accuracy: 0.3102 - lr: 1.0000e-05\n",
            "Epoch 78/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.3733e-08 - accuracy: 0.3223 - val_loss: 1.0317e-08 - val_accuracy: 0.3080 - lr: 1.0000e-05\n",
            "Epoch 79/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3622e-08 - accuracy: 0.3192 - val_loss: 1.0413e-08 - val_accuracy: 0.3077 - lr: 1.0000e-05\n",
            "Epoch 80/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.3621e-08 - accuracy: 0.3245 - val_loss: 1.0482e-08 - val_accuracy: 0.3110 - lr: 1.0000e-05\n",
            "Epoch 81/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3568e-08 - accuracy: 0.3217 - val_loss: 1.0644e-08 - val_accuracy: 0.3082 - lr: 1.0000e-05\n",
            "Epoch 82/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3951e-08 - accuracy: 0.3227 - val_loss: 1.0507e-08 - val_accuracy: 0.3096 - lr: 1.0000e-05\n",
            "Epoch 83/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3751e-08 - accuracy: 0.3236 - val_loss: 1.0240e-08 - val_accuracy: 0.3079 - lr: 1.0000e-05\n",
            "Epoch 84/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.3732e-08 - accuracy: 0.3215 - val_loss: 1.0828e-08 - val_accuracy: 0.3082 - lr: 1.0000e-05\n",
            "Epoch 85/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.3570e-08 - accuracy: 0.3271 - val_loss: 1.0385e-08 - val_accuracy: 0.3107 - lr: 1.0000e-05\n",
            "Epoch 86/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3416e-08 - accuracy: 0.3219 - val_loss: 1.0708e-08 - val_accuracy: 0.3079 - lr: 1.0000e-05\n",
            "Epoch 87/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3445e-08 - accuracy: 0.3218 - val_loss: 1.0451e-08 - val_accuracy: 0.3072 - lr: 1.0000e-05\n",
            "Epoch 88/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3732e-08 - accuracy: 0.3237 - val_loss: 1.0603e-08 - val_accuracy: 0.3088 - lr: 1.0000e-05\n",
            "Epoch 89/1000\n",
            "261/261 [==============================] - 17s 66ms/step - loss: 1.3584e-08 - accuracy: 0.3207 - val_loss: 1.0638e-08 - val_accuracy: 0.3086 - lr: 1.0000e-05\n",
            "Epoch 90/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.3505e-08 - accuracy: 0.3220 - val_loss: 1.0616e-08 - val_accuracy: 0.3053 - lr: 1.0000e-05\n",
            "Epoch 91/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3356e-08 - accuracy: 0.3197 - val_loss: 1.0694e-08 - val_accuracy: 0.3078 - lr: 1.0000e-05\n",
            "Epoch 92/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.3346e-08 - accuracy: 0.3207 - val_loss: 1.0448e-08 - val_accuracy: 0.3098 - lr: 1.0000e-05\n",
            "Epoch 93/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.3581e-08 - accuracy: 0.3204 - val_loss: 1.0758e-08 - val_accuracy: 0.3095 - lr: 1.0000e-05\n",
            "Epoch 94/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3664e-08 - accuracy: 0.3235 - val_loss: 1.0455e-08 - val_accuracy: 0.3072 - lr: 1.0000e-05\n",
            "Epoch 95/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3616e-08 - accuracy: 0.3247 - val_loss: 1.0240e-08 - val_accuracy: 0.3113 - lr: 1.0000e-05\n",
            "Epoch 96/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3432e-08 - accuracy: 0.3249 - val_loss: 1.0688e-08 - val_accuracy: 0.3073 - lr: 1.0000e-05\n",
            "Epoch 97/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3551e-08 - accuracy: 0.3224 - val_loss: 1.0544e-08 - val_accuracy: 0.3063 - lr: 1.0000e-05\n",
            "Epoch 98/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3603e-08 - accuracy: 0.3210 - val_loss: 1.1016e-08 - val_accuracy: 0.3064 - lr: 1.0000e-05\n",
            "Epoch 99/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3366e-08 - accuracy: 0.3206 - val_loss: 1.0756e-08 - val_accuracy: 0.3085 - lr: 1.0000e-05\n",
            "Epoch 100/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3445e-08 - accuracy: 0.3237 - val_loss: 1.0680e-08 - val_accuracy: 0.3071 - lr: 1.0000e-05\n",
            "Epoch 101/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3580e-08 - accuracy: 0.3234 - val_loss: 1.0493e-08 - val_accuracy: 0.3096 - lr: 1.0000e-05\n",
            "Epoch 102/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3685e-08 - accuracy: 0.3208 - val_loss: 1.0539e-08 - val_accuracy: 0.3067 - lr: 1.0000e-05\n",
            "Epoch 103/1000\n",
            "261/261 [==============================] - 17s 64ms/step - loss: 1.3439e-08 - accuracy: 0.3222 - val_loss: 1.0729e-08 - val_accuracy: 0.3061 - lr: 1.0000e-05\n",
            "Epoch 104/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3494e-08 - accuracy: 0.3227 - val_loss: 1.0768e-08 - val_accuracy: 0.3072 - lr: 1.0000e-05\n",
            "Epoch 105/1000\n",
            "261/261 [==============================] - 17s 65ms/step - loss: 1.3502e-08 - accuracy: 0.3223 - val_loss: 1.0448e-08 - val_accuracy: 0.3079 - lr: 1.0000e-05\n",
            "Epoch 106/1000\n",
            "115/261 [============>.................] - ETA: 9s - loss: 1.3368e-08 - accuracy: 0.3226"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}